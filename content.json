{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"http://example.com","root":"/"},"pages":[],"posts":[{"title":"","slug":"db","date":"2021-03-28T16:53:04.859Z","updated":"2021-03-28T16:53:04.859Z","comments":true,"path":"2021/03/29/db/","link":"","permalink":"http://example.com/2021/03/29/db/","excerpt":"","text":"数据库 数据库范式(Normal Form) 第一范式：确保每列保持原子性。 第一范式是最基本的范式。如果数据库表中的所有字段值都是不可分解的原子值，就说明该数据库表满足了第一范式。 第二范式：确保表中的每列都和主键相关 第二范式在第一范式的基础之上更进一层。第二范式需要确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。也就是说在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。 第三范式：确保每列都和主键列直接相关，而不是间接相关。或者说非主键之间不应该有依赖关系。 第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。 BC范式： BC范式（BCNF）是Boyce-Codd范式的缩写，其定义是：在关系模式中每一个决定因素都包含候选键，也就是说，只要属性或属性组A能够决定任何一个属性B，则A的子集中必须有候选键。BCNF范式排除了任何属性(不光是非主属性，2NF和3NF所限制的都是非主属性)对候选键的传递依赖与部分依赖。 第四范式：不存在多值依赖 数据库的索引（B树索引、哈希索引、位图索引）区别。 B树索引 不存储含有null的值(复合索引不能全为null) 不适合键值较少的列（重复数据较多的列） 前导模糊查询不能利用索引 位图索引 就是用位图表示的索引，对列的每个键值建立一个位图。 相对于b数索引，占用空间小，创建和使用非常快 不适合键值较多的列。 不适合update、insert、delete频繁的列。 可以存储null值 哈希索引 根据HASH算法来构建的索引，所以检索速度很快，但不能范围查询。 只适合等值查询（包括= &lt;&gt; 和in） 说下聚簇索引和非聚簇索引的区别 聚簇索引的顺序就是数据的物理存储顺序，而对非聚簇索引的解释是:索引顺序与数据物理排列顺序无关。正式因为如此，所以一个表最多只能有一个聚簇索引。我们可以这么理解聚簇索引：索引的叶节点就是数据节点。而非聚簇索引的叶节点仍然是索引节点，只不过有一个指针指向对应的数据块。 数据库索引的作用 加速访问 索引使用什么数据结构实现的 B树或者B+树 数据库引擎了解吗，INNODB和MYIASM的区别，效率上的差异，锁的差别 MySQL数据库引擎取决于MySQL在安装的时候是如何被编译的。要添加一个新的引擎，就必须重新编译MYSQL。在缺省情况下，MYSQL支持三个引擎：ISAM、MYISAM和HEAP。另外两种类型INNODB和BERKLEY（BDB），也常常可以使用。 ISAM：ISAM是一个定义明确且历经时间考验的数据表格管理方法，它在设计之时就考虑到数据库被查询的次数要远大于更新的次数。因此，ISAM执行读取操作的速度很快，而且不占用大量的内存和存储资源。ISAM的两个主要不足之处在于，它不支持事务处理，也不能够容错：如果你的硬盘崩溃了，那么数据文件就无法恢复了。如果你正在把ISAM用在关键任务应用程序里，那就必须经常备份你所有的实时数据，通过其复制特性，MYSQL能够支持这样的备份应用程序。 MyISAM：MyISAM是MySQL的ISAM扩展格式和缺省的数据库引擎。除了提供ISAM里所没有的索引和字段管理的大量功能，MyISAM还使用一种表格锁定的机制，来优化多个并发的读写操作，其代价是你需要经常运行OPTIMIZE TABLE命令，来恢复被更新机制所浪费的空间。MyISAM还有一些有用的扩展，例如用来修复数据库文件的MyISAMCHK工具和用来恢复浪费空间的 MyISAMPACK工具。MYISAM强调了快速读取操作，这可能就是为什么MySQL受到了WEB开发如此青睐的主要原因：在WEB开发中你所进行的大量数据操作都是读取操作。所以，大多数虚拟主机提供商和INTERNET平台提供商只允许使用MYISAM格式。MyISAM格式的一个重要缺陷就是不能在表损坏后恢复数据。 HEAP：HEAP允许只驻留在内存里的临时表格。驻留在内存里让HEAP要比ISAM和MYISAM都快，但是它所管理的数据是不稳定的，而且如果在关机之前没有进行保存，那么所有的数据都会丢失。在数据行被删除的时候，HEAP也不会浪费大量的空间。HEAP表格在你需要使用SELECT表达式来选择和操控数据的时候非常有用。要记住，在用完表格之后就删除表格。 InnoDB数据库引擎都是造就MySQL灵活性的技术的直接产品，这项技术就是MYSQL+API。在使用MYSQL的时候，你所面对的每一个挑战几乎都源于ISAM和MyISAM数据库引擎不支持事务处理（transaction process）也不支持外来键。尽管要比ISAM和 MyISAM引擎慢很多，但是InnoDB包括了对事务处理和外来键的支持，这两点都是前两个引擎所没有的。如前所述，如果你的设计需要这些特性中的一者或者两者，那你就要被迫使用后两个引擎中的一个了。 MyISAM和InnoDB的区别 总的来说，InnoDB和MyISAM是许多人在使用MySQL时最常用的两个表类型，这两个表类型各有优劣，视具体应用而定。基本的差别为：MyISAM类型不支持事务处理等高级处理，而InnoDB类型支持。MyISAM类型的表强调的是性能，其执行数度比InnoDB类型更快，但是不提供事务支持，而InnoDB提供事务支持已经外部键等高级数据库功能。 MyISAM的读性能是比Innodb强不少的。 MyISAM的索引和数据是分开的，并且索引是有压缩的，内存使用率就对应提高了不少。能加载更多索引，而Innodb是索引和数据是紧密捆绑的，没有使用压缩从而会造成Innodb比MyISAM体积庞大不小。 MyISAM适合 做很多count的计算 插入不频繁，查询非常频繁 没有事务。 InnoDB适合 可靠性要求比较高，或者要求事务 表更新和查询都相当的频繁，并且表锁定的机会比较大的情况指定数据引擎的创建。让所有的灵活性成为可能的开关是提供给ANSI SQL的MySQL扩展——TYPE参数。MySQL能够让你在表格这一层指定数据库引擎，所以它们有时候也指的是table formats。下面的示例代码表明了如何创建分别使用MyISAM、ISAM和HEAP引擎的表格。要注意，创建每个表格的代码是相同的，除了最后的 TYPE参数，这一参数用来指定数据引擎。 数据库事务 事务（Transaction）是由一系列对系统中数据进行访问与更新的操作所组成的一个程序执行逻辑单元。 四大特性： 原子性：事务的原子性是指事务必须是一个原子的操作序列单元。事务中包含的各项操作在一次执行过程中，只允许出现两种状态之一(要么全部成功要么全部失败)。任何一项操作都会导致整个事务的失败，同时其它已经被执行的操作都将被撤销并回滚，只有所有的操作全部成功，整个事务才算是成功完成。 一致性：事务的一致性是指事务的执行不能破坏数据库数据的完整性和一致性，一个事务在执行之前和执行之后，数据库都必须处以一致性状态。 隔离性：事务的隔离性是指在并发环境中，并发的事务是互相隔离的，一个事务的执行不能被其它事务干扰。也就是说，不同的事务并发操作相同的数据时，每个事务都有各自完整的数据空间。 隔离级别有四个：读未提及、读已提交(解决脏读)、可重复读（解决不可重读）、顺序读（严格并发、解决幻读），mysql默认是可重复读 隔离性解决的问题：脏渎、不可重读、幻读（理解这三者的区别） 永久性：事务的持久性是指事务一旦提交后，数据库中的数据必须被永久的保存下来。即使服务器系统崩溃或服务器宕机等故障。只要数据库重新启动，那么一定能够将其恢复到事务成功结束后的状态。 隔离的实现 隔离的实现也是依赖加锁机制, InnoDB存在两种锁:S锁(共享锁)和X锁(排它锁) 查询优化 合理建立索引、优化SQL语句 IN、EXTISTS、JOIN的区别和应用场景 in在查询的时候，首先查询子查询的表，然后将内表和外表做一个笛卡尔积，然后按照条件进行筛选。所以相对内表比较小的时候，in的速度较快。in是把外表和内表作hash 连接，而exists 是对外表作loop循环，每次loop循环再对内表进行查询。 IN适合于外表大而内表小的情况；EXISTS适合于外表小而内表大的情况 防止索引失效 在分库之后，如何设计idhttps://blog.csdn.net/xiaoningxueJAVA/article/details/108336568 在分库后，一条插入请求，在上层不做处理，如何直接在数据库找到相应的库并插入库中的某个表 MySQL怎么进行数据存储肯定是存储在文件中，那又是怎么做到可以通过索引快速查询？ 1，每个数据库对应一个文件夹，文件夹名和库名相同； 2，(单独的表空间中) 每张表对应几个文件，文件名和表名相同，innodb引擎中对应两个文件，后缀名为：frm、ibd； frm文件：存储的是表结构信息。 ibd文件：存储的是表里的数据、索引等。 多个Page在一起构成一颗多路平衡树, Page作为树的节点, 在平衡树的基础上, 同一层的节点左右相连, 所以称为B+树;树中: 非叶子节点保存主键和子节点的位置, 叶子节点保存完整的记录; 如果让你设计数据库，你会想到那些优化 表空间分离。最起码user和其他应用不应该使用系统表空间。表空间应该分在不同物理存储上，实现表空间分离 开启慢查询日志、善用MySql内部函数explain 善用不同的存储引擎，MySQL有多种不同的存储引擎，InnoDB，Aria，MEMORY根据需要给不同的表选择不同的存储引擎，比如要支持transaction的话用InnoDB等 表很大的时候，做分表查询，有水平分割、垂直分割垂直切分的优点如下： 拆分后业务清晰，拆分规则明确。系统之间进行整合或扩展很容易。按照成本、应用的等级、应用的类型等奖表放到不同的机器上，便于管理。便于实现动静分离、冷热分离的数据库表的设计模式。数据维护简单。垂直切分的缺点如下： 部分业务表无法关联(Join), 只能通过接口方式解决，提高了系统的复杂度。受每种业务的不同限制，存在单库性能瓶颈，不易进行数据扩展和提升性能。事务处理复杂。 我们把冷热数据分开存放，就叫作冷热分离，在MySQL的数据库中，冷数据查询较多，更新较少，适合用MyISAM引擎，而热数据更新比较频繁，适合使用InnoDB存储引擎，这也是垂直拆分的一种。 水平切分的优点如下： 单库单表的数据保持在一定的量级，有助于性能的提高。切分的表的结构相同，应用层改造较少，只需要增加路由规则即可。提高了系统的稳定性和负载能力。水平切分的缺点如下： 切分后，数据是分散的，很难利用数据库的Join操作，跨库Join性能较差。拆分规则难以抽象。分片事务的一致性难以解决。数据扩容的难度和维护量极大。 读写分离https://baijiahao.baidu.com/s?id=1614304400276051465&amp;wfr=spider&amp;for=pchttps://blog.csdn.net/u013421629/article/details/78793966 应该创建索引的字段 经常作为查询条件的字段 经常用在多表连接的列，例如外键 经常需要排序的字段 应该少建或者不建索引的情况 表中数据太少，增加索引基本不会带来查询速度的提升，反而浪费了存储空间。 经常需要插入、修改、删除操作的表 表中数据重复且分布平均的字段(如“性别”) 务必不要使用select * ，尽量使用limit，优化的目的就是尽量不去做全表扫描 频繁查询的where子语句的条件加上索引 where子语句的连接不要使用or，这样会使引擎放弃索引，直接全表扫描 sql语句不要做太多关联，最好简单分开 一个表有用户id.和用户成绩，怎么找到成绩前10的人。 SELECT * FROM( SELECT T.*, ROW_NUMBER() OVER(PARTITION BY 班级 ORDER BY 成绩 DESC) RN FROM T ) WHERE RN&lt;=10 数据库中char和varchar2的区别，和使用场景。 char长度不可变，varchar2长度可变。char效率比varchar2效率稍高，但char浪费更多空间。varchar2把所有字符都占两字节处理（一般情况下），varchar只对汉字和全角等字符占两字节，数字，英文字符等都是一个字节； 怎么防止sql注入（危险字符的转义，对SQL预编译）https://blog.csdn.net/qq_35868412/article/details/82012105 1.预编译2.使用正则表达式过滤传入的参数3.字符串过滤4.jsp中调用该函数检查是否包函非法字符5.JSP页面判断代码 Redis缓存机制：应用场景和优点、与memcache的区别、如何实现持久性、主从模式 读写分离、主从复制、主从复制的方式https://www.jianshu.com/p/d325daedabaa 1.同步复制2.异步复制3.半同步复制 sql语句写 一个属性的查询，分组，计数并排序输出。https://blog.csdn.net/duoshanx/article/details/1505371 一段不连续的内存，怎么才可以实现键值对快速更新、查询 redis为什么性能高？ 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1) 数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗 使用多路I/O复用模型，非阻塞IO 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求 redis可以做什么，mysql buffer pool 可以做缓存吗？ redis有没有用过，常用的数据结构以及在业务中使用的场景，redis的hash怎么实现的。redis cluster有没有了解过，怎么做到高可用的？redis的持久化机制，为啥不能用redis做专门的持久化数据库存储？ Redis内存数据库的内存指的是共享内存么 从A表中选出B表没有的数据，就是AB表有一个共同列，这个列中序号的不同的A表的数据全部拿出来 select * from A where t2 not in (select t2 from B) nosql SQL语句，查询两个数据库表中ID相同的信息。 SELECT information from table_1 left join table_2 where table_1.ID = table_2.ID redis的缺陷 数据存放在私有内存，升级版本和更新困难，且危险性高 内存使用率低，碎片多 备份、全量同步机制采用fork+rdb的方式，且对内存增长没有做控制 死机恢复采用全量+增量方式，如果数据量太大并且写量也足够大，有可能占用大量buffer缓冲且出现反复失败的情况 对于所有命令串行处理，有些慢查询如lrange会阻塞其他命令 存在大包回复时，可能会消耗一大块内存用于存放临时对象 没有防雪崩之类的海量数据运营机制 脑筋急转弯 36匹马6个跑道无秒表选前三，最少跑几轮。 8轮，link 有八只小白鼠，八瓶要其中有一瓶毒药，药发时间是一小时，问最小用几只小白鼠能找出毒药。 二分法，每次把试剂分成两堆，然后用两只小鼠测试，如果一只死掉了，那么就能确定哪一堆有毒。然后继续分。因此，小鼠的数量就是试剂能被二分的次数。8只试剂能被二分3次，所以就需要3值小鼠。 5L 6L空瓶子，弄出3L水 傻逼题 有一只股票，原价为p0,若它涨停10天后又跌停10天后得到p1,若它跌停10天再涨停10天得到p2，求三者关系（p0 &gt; p1 = p2) 有25匹马，五个赛道，用最少比赛次数将25匹马排序 毫无悬念，一匹马只有跑了才能看出其速度，25匹马至少都跑了一次，最少五轮，且每轮能排出名次；由于最终只要最快的三名，顾每组只有1、2、3有意义继续比下去，4、5名直接淘汰。每组的3有意义的前提是该组的2就是总排名的2、1就是总排名的1，每组的2有意义的前提是该组的1至少第二；归根到底还是看每组第一的情况，故5个第一比一次，第一就是总的第一；第四、第五及其所在的组全部被淘汰；故第一的组的二、三名，第二的组第一、二名；第三的组的第一名比最后一次，前两名就是总的二、三名；共七轮。 a1,a2,a3,a4,a5;------&gt;a1,a2,a3; b1,b2,b3,b4,b5;------&gt;b1,b2,b3; c1,c2,c3,c4,c5;------&gt;c1,c2,c3; d1,d2,d3,d4,d5;------&gt;d1,d2,d3; e1,e2,e3,e4,e5;------&gt;e1,e2,e3; a1,b1,c1,d1,e1;——&gt; a1 ,b1,c1 a2,a3,b1,b3,c1;——&gt; a2,a3 ; 有100层楼，你有两部手机，请用最少的次数测试出在第几层手机会被摔碎 14，link 软件工程 在项目中用到过设计模式吗？讲讲工厂模式，用工厂模式制造不同的单例出来 对于单例模式，有什么使用场景了，讲了全局id生成器，他问我分布式id生成器怎么实现，说了zk，问我zk了解原理不，讲了zab 适配器模式怎么实现么，有什么用 多线程下如何实现单例，加锁？怎么加？synchronized，synchronized在静态方法、实例方法、代码块前使用的区别 7种结构模式以及应用场景：桥接模式、适配器模式、代理模式、享元模式、组合模式、门面模式、装饰模式 重点掌握单例模式和MVC模式（应用场景、优缺点） 了解UML图，能看懂各种不同箭头表示的意思。 写你知道的Git命令 git init git pull git fetch git merge 在本地新建一个temp分支，并将远程origin仓库的master分支代码下载到本地temp分支；$ git fetch origin master:temp 比较本地代码与刚刚从远程下载下来的代码的区别；$ git diff temp 合并temp分支到本地的master分支;$ git merge temp 如果不想保留temp分支，删除;$ git branch -d temp git add git commit git push git reset –hard git stash git stash pop 单例模式、懒汉饿汉 分布式系统 有了解分布式系统吗？ 现有开源分布式存储的系统或协议是否了解 数据同步、单点故障、副本容灾、读写一致性等 一致性哈希 知道cap原则吗？ 知道dubbo吗 其他 现在要完成一个微博评论的部分，想在用户进入新闻时优先看到自己好友对此新闻的评论，好友可能有多条评论，怎么设计结构。 我现在想要写一个简单的web服务器，响应用户相应的数据，该怎么写（首先创建一个服务器socket，然后bind地址，listen监听，然后把socket加入多路转接监听链表。当有连接到达的时候，我们对socket调用accept，返回一个已连接套接字描述符，然后根据用户传输过来的文件名去查找文件，读取文件内容并回送给用户（被打断）读取文件的时候服务器socket怎么办呢，accept之后创建一个线程，如果使用线程池的话就从池中取一个空闲线程，然后把已连接文件描述符传给这个线程，然后让线程去处理这个用户请求） 假设我想要缓存web服务器的访问记录，该如何实现这个数据结构（用队列吧，根据last visited排序，先进先出，如果你用队列的话，你怎么确定cache是否命中呢，你根据什么判断是否命中，key，那我还是用队列，每一个元素包含键值两部分，值的话呢就是访问的记录。然后我再用一个红黑树保存键值，这个值呢是指向队列元素的指针，其实用hash表更好一点，这样更快，但是我一般都比较喜欢用红黑树…） 在记录有用户上线下线的日志文件中查询某个时间点的在线人数。时间复杂度多少，能不能优化？ 然后问有一个图像处理程序，处理一个请求需要50ms的cpu计算，现在打算部署到4核CPU上，问设置几个线程合适。再扩展，假如不仅需要50ms的cpu计算，还需要200ms的IO时间，问设置几个线程合适。 要是设计一个高并发服务器，可以从哪些角度去优化。 假如有一亿QQ用户，每个用户都有500好友，每个人都可能玩很多腾讯出的游戏，问如何存储能使获取一个人的好友玩的游戏列表。 我想了半天，说不会，最后被提醒用kv存储，面试官让我回去看看bitmap，这一部分是印象最深耗时最长的部分。 直播的架构怎么设计么，要点是什么，说了几个不太对，他说要避免广播风暴，答不会。","categories":[],"tags":[]},{"title":"","slug":"network","date":"2021-03-25T10:21:22.300Z","updated":"2021-03-25T10:21:22.300Z","comments":true,"path":"2021/03/25/network/","link":"","permalink":"http://example.com/2021/03/25/network/","excerpt":"","text":"计算机网络 OSI七层模型和TCP/IP五层模型 名称 作用 协议 应用层 文件传输、电子邮件、虚拟终端等 HTTP，SNMP，FTP，SMTP，DNS，Telnet 表示层 数据格式化，代码转换，数据加密，压缩解压 没有协议 会话层 解除或建立与别的接点的联系 （对话的建立维护以及同步） 没有协议 传输层 提供端对端的接口 TCP，UDP，SPX 网络层 为数据包选择路由 IP，ICMP，RIP，OSPF，BGP，IGMP 数据链路层 传输有地址的帧以及错误检测功能 SLIP，CSLIP，PPP，ARP，RARP，MTU 物理层 以二进制数据形式在物理媒体上传输数据 ISO2110，IEEE802，IEEE802.2 TCP/IP层 网络设备 应用层 软件 传输层 四层交换机、也有工作在四层的路由器 网络层 路由器、三层交换机 数据链路层 网桥、交换机、网卡(一半数据链路一半物理) 物理层 中继器、集线器、双绞线 网络层、数据链路层、传输层使用的寻址地址分别是什么 ip地址，mac地址，ip:端口号 常见的应用层协议和相对端口号 FTP：20,21；SSH：22；Telent：23；HTTP：80；HTTPS：443；DNS：53；DHCP：67；mysql：3306；tomcat：8080；oracle：1521、1526；SMTP：25 常见HTTP响应状态码 200 ok;301 网页已移除；400 坏请求；404 not found；505 不支持该http版本； 1：响应 2：成功响应 3：重定向 4：客户端错误 5：服务器错误 IP地址的分类 现在的IP网络使用32位地址，以点分十进制表示，如172.16.0.0。地址格式为：IP地址=网络地址＋主机地址 或 IP地址=主机地址＋子网地址＋主机地址。 IP地址根据网络ID的不同分为5种类型，A类地址、B类地址、C类地址、D类地址和E类地址。 A类：一个A类IP地址由1字节的网络地址和3字节主机地址组成，网络地址的最高位必须是“0”， 地址范围从1.0.0.0 到126.0.0.0。可用的A类网络有126个，每个网络能容纳1亿多个主机。默认掩码为255.0.0.0 B类：一个B类IP地址由2个字节的网络地址和2个字节的主机地址组成，网络地址的最高位必须是“10”，地址范围从128.0.0.0到191.255.255.255。可用的B类网络有16382个，每个网络能容纳6万多个主机。默认掩码为255.255.0.0 C类：一个C类IP地址由3字节的网络地址和1字节的主机地址组成，网络地址的最高位必须是“110”。范围从192.0.0.0到223.255.255.255。C类网络可达209万余个，每个网络能容纳254个主机。默认掩码为255.255.255.0 D类：D类地址称为广播地址，供特殊协议向选定的节点发送信息时用，网络地址的最高位必须是“1110”。范围从224.0.0.0~239.255.255.255 E类：E类地址说是留给将来用，但其实现在应该用完了吧，网络地址的最高位必须是“11110”。范围从240.0.0.0~255.255.255.254 全零(0.0.0.0)代表当前主机，全1(255.255.255.255)代表当前子网的广播地址 在IP地址3种主要类型里，各保留了3个区域作为私有地址，其地址范围如下 A类地址：10.0.0.0～10.255.255.255 (10全部) B类地址：172.16.0.0～172.31.255.255 C类地址：192.168.0.0～192.168.255.255 (192.168全部) 注意，0和127开头不属于A类地址，0代表任何地址，127为回环测试地址。回环测试地址保留给内部回送函数，数字0表示该地址为本地宿主机，不能传送 子网掩码的作用 子网掩码只有一个作用，就是将某个IP地址划分成网络地址和主机地址两部分。 子网掩码是一个32位地址，对于A类地址来说，默认的子网掩码是255.0.0.0；对于B类地址来说默认的子网掩码是255.255.0.0；对于C类地址来说默认的子网掩码是255.255.255.0。 如何确定子网掩码 如欲将B类IP地址168.195.0.0划分成若干子网，每个子网内有主机700台 700=1010111100，该二进制为十位数，N = 10 将子网掩码255.255.255.255从后向前的10位全部置0，即为11111111.11111111.11111100.00000000，也即255.255.252.0。255.255.252.0就是168.195.0.0的700台主机的子网掩码了。 如何将一个ip地址由点分制和int类型间进行相互转化 点分制的ip地址相比正常的二进制转成十进制，只不过是每八位都少乘了一个$2^{8*n}$而已（n从0开始） 10.10.1.1的十进制就是$102^{83}+102^{82}+12^{81}+12^{80}=168427777$ TCP三次握手、四次挥手。 需要注意的是， 上图中出现的 ACK = x +1 的写法很容易让人误以为数据包中的 ACK 域的数据值被填成了 x+1 。 ACK = x+1 的实际含义是： TCP 包的 ACK 标志位（1 bit） 被置成了 1 TCP 包的确认号（acknowledgement number ） 的值为 x+1 类似的， TCP 数据包中的 SYN 标志位， 也容易与序号（sequence number） 混淆， 这点需要读者注意 为什么三次握手最后一次握手中， 在上面的示意图中回复的 seq = x+1 而不是 x+2 为什么tcp连接要握手，为什么一定要三次，两次会有什么后果？ 这里就引出了 TCP 与 UDP 的一个基本区别， TCP 是可靠通信协议， 而 UDP 是不可靠通信协议。 TCP 的可靠性含义： 接收方收到的数据是完整， 有序， 无差错的。 UDP 不可靠性含义： 接收方接收到的数据可能存在部分丢失， 顺序也不一定能保证。 TCP 协议为了实现可靠传输， 通信双方需要判断自己已经发送的数据包是否都被接收方收到， 如果没收到， 就需要重发。 为了实现这个需求， 很自然地就会引出序号（sequence number） 和确认号（acknowledgement number）的使用。 为了实现可靠传输，发送方和接收方始终需要同步( SYNchronize )序号。 需要注意的是， 序号并不是从 0 开始的， 而是由发送方随机选择的初始序列号 ( Initial Sequence Number, ISN )开始 。 由于 TCP 是一个双向通信协议， 通信双方都有能力发送信息， 并接收响应。 因此， 通信双方都需要随机产生一个初始的序列号， 并且把这个起始值告诉对方，并确认对方的同步序号。 链接 tcp协议格式，问tcp包里面有ip地址吗 TCP封装在IP报文中的时候，如下图所示，TCP头紧接着IP头(IPV6有扩展头的时候，则TCP头在扩展头后面)，不携带选项(option)的TCP头长为20bytes，携带选项的TCP头最长可到60bytes。 其中header length字段由4比特构成，最大值为15，单位是32比特，即头长的最大值为15*32 bits = 60bytes，因此上面说携带选项的TCP头长最长为60bytes。 tcp包的长度由MTU决定，一般是1500，最大传输大小(MSS)为1500-IP数据包包头(20bytes)-tcp数据包包头(20bytes)==1460bytes tcp何如保证数据可靠传输 主要靠5点： 确认和超时重传 数据合理分片和排序 流量控制 拥塞控制 数据校验 tcp超时重传 对于一些出错，超时丢包等问题TCP设计的超时与重传机制，其基本原理：在发送一个数据之后，就开启一个定时器，若是在这个时间内没有收到发送数据的ACK确认报文，则对该报文进行重传，在达到一定次数还没有成功时放弃并发送一个复位信号。 这里比较重要的是重传超时时间，怎样设置这个定时器的时间（RTO），从而保证对网络资源最小的浪费。因为若RTO太小，可能有些报文只是遇到拥堵或网络不好延迟较大而已，这样就会造成不必要的重传。太大的话，使发送端需要等待过长的时间才能发现数据丢失，影响网络传输效率。 由于不同的网络情况不一样，不可能设置一样的RTO，实际中RTO是根据网络中的RTT（传输往返时间）来自适应调整的。具体关系参考相关算法。 tcp慢启动 慢启动是TCP的一个拥塞控制机制，慢启动算法的基本思想是当TCP开始在一个网络中传输数据或发现数据丢失并开始重发时，首先慢慢的对网路实际容量进行试探，避免由于发送了过量的数据而导致阻塞。 慢启动为发送方的TCP增加了另一个窗口：拥塞窗口(congestion window)，记为cwnd。当与另一个网络的主机建立TCP连接时，拥塞窗口被初始化为 1个报文段（即另一端通告的报文段大小）。每收到一个ACK，拥塞窗口就增加一个报文段（cwnd以字节为单位，但是慢启动以报文段大小为单位进行增加）。发送方取拥塞窗口与通告窗口中的最小值作为发送上限。拥塞窗口是发送方使用的流量控制，而通告窗口则是接收方使用的流量控制。发送方开始时发送一个报文段，然后等待 ACK。当收到该ACK时，拥塞窗口从1增加为2，即可以发送两个报文段。当收到这两个报文段的 ACK时，拥塞窗口就增加为4。这是一种指数增加的关系。 tcp拥塞避免 网络中拥塞的发生会导致数据分组丢失，需要尽量避免。在实际中，拥塞算法与慢启动通常在一起实现，其基本过程： 对一个给定的连接，初始化cwnd为1个报文段，ssthresh为65535个字节。 TCP输出例程的输出不能超过cwnd和接收方通告窗口的大小。拥塞避免是发送方使用的流量控制，而通告窗口则是接收方进行的流量控制。前者是发送方感受到的网络拥塞的估 计，而后者则与接收方在该连接上的可用缓存大小有关。 当拥塞发生时（超时或收到重复确认），ssthresh被设置为当前窗口大小的一半（cwnd 和接收方通告窗口大小的最小值，但最少为2个报文段）。此外，如果是超时引起了拥塞，则 cwnd被设置为1个报文段（这就是慢启动）。 当新的数据被对方确认时，就增加cwnd，但增加的方法依赖于是否正在进行慢启动或拥塞避免。如果cwnd小于或等于ssthresh，则正在进行慢启动，否则正在进行拥塞避免。慢启动一直持续到回到当拥塞发生时所处位置的半时候才停止（因为记录了在步骤2 中制造麻烦的窗口大小的一半），然后转为执行拥塞避免。 客户端当被告知服务端接收窗口大小为0后的行为，如果服务端的接收窗口又变大了呢？ 如果窗口尺寸是 0，发送端就将发出一个探测信号以搞清这个窗口什么时间再次打开。如果发送方从来没有收到ACK信息，它就一直不断地重试，直到定时器过期。又变大就继续发。 tcp滑动窗口（整个流程、接收窗口和发送窗口是如何移动的、序列和确认号）、拥塞控制掌握三个阶段：慢启动、拥塞避免、超时重传/快速恢复） 先来看从概念上数据分为哪些类 Sent and Acknowledged：这些数据表示已经发送成功并已经被确认的数据，比如图中的前31个bytes，这些数据其实的位置是在窗口之外了，因为窗口内顺序最低的被确认之后，要移除窗口，实际上是窗口进行合拢，同时打开接收新的带发送的数据 Send But Not Yet Acknowledged：这部分数据称为发送但没有被确认，数据被发送出去，没有收到接收端的ACK，认为并没有完成发送，这个属于窗口内的数据。 Not Sent，Recipient Ready to Receive：这部分是尽快发送的数据，这部分数据已经被加载到缓存中，也就是窗口中了，等待发送，其实这个窗口是完全有接收方告知的，接收方告知还是能够接受这些包，所以发送方需要尽快的发送这些包 Not Sent，Recipient Not Ready to Receive： 这些数据属于未发送，同时接收端也不允许发送的，因为这些数据已经超出了发送端所接收的范围 对于发送方来讲，窗口内的包括两部分，发送窗口（已经发送了，但是没有收到ACK），接收端允许发送但是没有发送的那部分称为可用窗口。 对于接收端也是有一个接收窗口，类似发送端，接收端的数据有3个分类，因为接收端并不需要等待ACK所以它没有类似的接收并确认了的分类，情况如下 Received and ACK Not Send to Process：这部分数据属于接收了数据但是还没有被上层的应用程序接收，也是被缓存在窗口内 Received Not ACK: 已经接收并，但是还没有回复ACK，这些包可能输属于Delay ACK的范畴了 Not Received：有空位，还没有被接收的数据。 TCP并不是每一个报文段都会回复ACK的，可能会对两个报文段发送一个ACK，也可能会对多个报文段发送1个ACK（累计ACK） 链接 在四次挥手的时候会有一个wait的过程，目的是什么，time_wait连接过多如何解决 简单来说，time_wait状态是四次挥手中server向client发送FIN终止连接后client进入的状态。time_wait状态存在于client收到serverFin并返回ack包时的状态。当处于time_wait状态时，由于port被占用，我们无法创建新的连接。有时产生在server端，由于server主动断开连接或者发生异常。 存在原因 可靠地终止TCP连接，若处于time_wait的client发送给server确认报文段丢失的话，server将在此又一次发送FIN报文段，那么client必须处于一个可接收的状态就是time_wait而不是close状态。 保证迟来的TCP报文段有足够的时间被识别并丢弃，linux 中一个TCPport不能打开两次或两次以上。当client处于time_wait状态时我们将无法使用此port建立新连接，假设不存在time_wait状态，新连接可能会收到旧连接的数据。 time_wait持续的时间是2MSL，保证旧的数据能够丢弃。 在高并发短连接的TCP服务器上，当服务器处理完请求后立刻按照主动正常关闭连接。这个场景下，会出现大量socket处于TIMEWAIT状态。如果客户端的并发量持续很高，此时部分客户端就会显示连接不上。 如何处理？sysctl改两个内核参数就行了，如下：net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_tw_recycle = 1简单来说，就是打开系统的TIMEWAIT重用和快速回收 udp的特征 无连接 尽最大努力交付 面向报文 没有拥塞控制 支持一对一、一对多、多对一、多对多的交互通信 首部开销小 知道udp是不可靠的传输，如果你来设计一个基于udp差不多可靠的算法，怎么设计？ 设计思路 数据完整性 –&gt; 加上一个16或者32位的CRC验证字段 乱序 –&gt; 加上一个数据包序列号SEQ 丢包 –&gt; 需要确认和重传机制，就是和Tcp类似的Ack机制 协议字段 –&gt; protol 字段，标识当前使用协议 udp的使用场景 面向数据报时 网络数据大多为短消息 拥有大量client 对数据安全性没有特殊要求 网络负担重，但要求高响应 tcp和udp的区别 TCP 面向连接，UDP 是无连接的； TCP 提供可靠的服务，也就是说，通过 TCP 连接传送的数据，无差错，不丢失，不重复，且按序到达；UDP 尽最大努力交付，即不保证可靠交付 TCP 的逻辑通信信道是全双工的可靠信道；UDP 则是不可靠信道 每一条 TCP 连接只能是点到点的；UDP 支持一对一，一对多，多对一和多对多的交互通信 TCP 面向字节流（可能出现黏包问题），实际上是 TCP 把数据看成一连串无结构的字节流；UDP 是面向报文的（不会出现黏包问题） UDP 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 IP 电话，实时视频会议等） TCP 首部开销20字节；UDP 的首部开销小，只有 8 个字节 tcp对半开链接的处理 当客户端与服务器建立起正常的TCP连接后，如果客户主机网线断开、电源掉电、或系统崩溃，服务器进程将永远不会知道（通过我们常用的select，epoll监测不到断开或错误事件），如果不主动处理或重启系统的话对于服务端来说会一直维持着这个连接，任凭服务端进程如何望穿秋水，也永远再等不到客户端的任何回应。这种情况就是半开连接，浪费了服务器端可用的文件描述符。 说明网线断开对端是不能做任何感知的，除非我们配置操作系统的SO_KEEPALIVE选项，或者进行应用层心跳检测 如果网线断开的时间短暂，在SO_KEEPALIVE设定的探测时间间隔内，并且两端在此期间没有任何针对此长连接的网络操作。当连上网线后此TCP连接可以自动恢复，继续进行正常的网络操作。 如果网线断开的时间很长，超出了SO_KEEPALIVE设定的探测时间间隔，或者两端期间在此有了任何针对此长连接的网络操作。当连上网线时就会出现ETIMEDOUT或者ECONNRESET的错误。你必须重新建立一个新的长连接进行网络操作。 tcp与udp编程步骤： tcp编程的服务器端步骤如下： 创建一个socket并设置socket属性 绑定IP地址、端口等信息到socket上 开启监听并接收客户端上来的连接 收发数据 关闭网络连接并关闭监听 tcp编程的客户端步骤如下： 创建一个socket并设置socket属性 绑定IP地址、端口等信息到socket上 设置要连接的对方的IP地址和端口等属性 连接服务器 收发数据 关闭网络连接 udp编程的服务器端步骤如下： 创建一个socket并设置socket属性 绑定IP地址、端口等信息到socket上 循环接收数据 关闭网络连接 udp编程的客户端步骤如下： 创建一个socket并设置socket属性 绑定IP地址、端口等信息到socket上 设置对方的IP地址和端口等属性 发送数据 关闭网络连接 如何完全消除time await? 当初回答的时候设置属性和reuse都是判错的，要求从最后挥手的阶段开始分析 粘包与处理 TCP协议允许发送端将几次发送的数据包缓存起来合成一个数据包发送到网络上去，因为这样可以获得更高的效率，这一行为通常是在操作系统提供的SOCKET中实现，所以在应用层对此毫无所觉。所以我们在程序中调用SOCKET的send发送了数据后操作系统有可能缓存了起来，等待后续的数据一起发送，而不是立即发送出去。send的文档中对此也有说明。 网络传输的概念中有MTU的概念，也即是网络中一个数据包最大的长度。如果要发送超过这个长度的数据包，就需要分包发送。当调用SOCKET的send发送超过MTU的数据包时，操作系统提供的SOCKET实现会自动将这个数据包分割成几个不超过MTU的数据包发送。 当出现这些上面这些情况的时候，接收端就会发现接收到的数据和发送的数据的次数不一致。这个就是粘包现象。当我们传输如文件这种数据时，流式的传输非常适合，但是当我们传输指令之类的数据结构时，流式模型就有一个问题：无法知道指令的结束。所以粘包必须问题是必须解决的。 最简单的方法就是短连接，也就是需要发送数据的时候建立TCP连接，发送完一个数据包后就断开TCP连接，这样接收端自然就知道数据结束了。但是这样的方法因为会多次建立TCP连接，性能低下。随便用用还可以，只要稍微对性能有一点追求的人就不会使用这种方法。 使用长连接能够获得更好的性能，但不可避免的会遇到如何判断数据结构的开始与结束的问题。而此时的处理方式根据数据结构的类型分两种方式。 定长结构：因为粘包问题的存在，接收端不能想当然的以为发送端一次发送了多少数据就能一次收到多少数据。如果发送端发送了一个固定长度的数据结构，接收端必须每次都严格判断接收到数据的长度，当收到的数据长度不足时，需要再次接收数据，直到满足长度，当收到的数据多于固定长度时，需要截断数据，并将多余的数据缓存起来，视为长度不足需要再次接收处理。 不定长结构：定长的数据结构是一种理想的情况，真正的应用中通常使用的都是不定长的数据结构。对于发送不定长的数据结构，简单的做法就是选一个固定的字符作为数据包结束标志，接收到这个字符就代表一个数据包传输完成了。但是这只能应用于字符数据，因为二进制数据中很难确定结束字符到底是结束还是原本要传输的数据内容。目前最通用的做法是在每次发送的数据的固定偏移位置写入数据包的长度。接收端只要一开始读取固定偏移的数据就可以知道这个数据包的长度，接下来的流程就和固定长度数据结构的处理流程类似。所以对于处理粘包的关键在于提前获取到数据包的长度，无论这个长度是提前商定好的还是写在在数据包的开头。因为在每次发送的数据的固定偏移位置写入数据包的长度的方法是最通用的一种方法，所以对这种方法实现中的一些容易出错误的地方在此特别说明。 通常我们使用2~4个字节来存放数据长度，多字节数据的网络传输需要注意字节序，所以要注意接受者和发送者要使用相同的字节序来解析数据长度。 每次新开始接收一段数据时不要急着直接去解析数据长度，先确保目前收到的数据已经足够解析出数据长度，例如数据开头的2个字节存储了数据长度，那么一定确保接收了2个字节以上的数据后才去解析数据长度。如果没做到这一点的服务器代码，收到了一个字节就去解析数据长度的，结果得到的长度是内存中的随机值，结果必然是崩溃的 有些非法客户端或者有bug的客户端可能会发出错误的数据，导致解析出的数据长度异常的大，一定要对解析出的数据长度做检查，事先规定一个合适的长度，一旦超过果断关闭SOCKET，避免服务器无休止的等待下去浪费资源。 处理完一个完整的数据包后一定检查是否还有未处理的数据，如果有的话要对这段多余的数据再次开始解析数据长度的过程。不要忙着去继续接受数据。 如何处理syn flood攻击 SYN Flood (SYN洪水) 是种典型的DoS (Denial of Service，拒绝服务) 攻击。效果就是服务器TCP连接资源耗尽，停止响应正常的TCP连接请求。攻击方A可以控制肉鸡向B发送大量SYN消息但不响应ACK消息，或者干脆伪造SYN消息中的Source IP，使B反馈的SYN-ACK消息石沉大海，导致B被大量注定不能完成的半开连接占据，直到资源耗尽，停止响应正常的连接请求。 最简单粗暴的办法就是提高TCP端口连接容量的同时减少半开连接的资源占用时间，也可以减少半开状态下等待ACK消息的时间或者重试发送SYN-ACK消息的次数，抑或启用某种半开连接回收机制，使得当半开连接队列满了以后做“除旧迎新”操作，当然并不是所有系统都支持这种机制。但攻击者只要稍稍改变策略就可以提高攻击效果，比如当使用半开连接回收机制时，攻击者只需提高攻击频率就可使大部分正常的等待的半开连接，在ACK消息到来前就被踢出队列。 以上两个思路都没有直击症结所在–任何一个SYN消息无论来源是谁，都会消耗B的一些资源保存半开状态，并逐渐达到“鸠占鹊巢”的效果。SYN Cache和SYN Cookies就是基于这个观察提出的两个方案。 SYN Cache的出发点主要是针对“鸠占鹊巢”问题，基本原理如下：构造一个全局的哈希表，用来缓存系统当前所有的半开连接信息，连接成功则从Cache中清除相关信息；Hash Table中每个桶（bucket）的容量大小也有限制，当桶“满”时做除旧迎新操作。当B收到一个SYN消息后，会将半开连接信息加入到Hash Table中，其中key的生成很关键，既要用到SYN消息中包含的信息（如：Source IP，Port等）又要做到很难被攻击者猜到，一般会通过一个秘密的函数生成，这样所有的半开连接无论好坏，都看似随机地被平均分配到了不同的“桶”中，使攻击难度大增，因为为达到DoS效果，攻击者需要使每个桶都达到填满状态，并且还要有足够快的“填桶”速度，使得正常的半开连接在还未完成建立前就被踢出桶，这样的攻击行为估计在达到目的前早就暴露了。 SYN Cookies着眼点主要是设法消除半开连接的资源消耗，原理与HTTP Cookies技术类似，B通过特定的算法把半开连接信息编码成“Cookie”，用作B给A的消息编号（SequenceNum），随SYN-ACK消息一同返回给连接发起方A，这样在连接完全建立前B不保存任何信息。如果A是正常用户，则会向B发送最后一次握手消息（ACK），B收到后验证“Cookie”的内容并建立连接；如果A是攻击者，则不会向B反馈ACK消息，B也没任何损失，也就说是单纯的SYN攻击不会造成B的连接资源消耗。当然这种方案也有一定缺点，最明显的就是B不保存连接的半开状态，就丧失了重发SYN-ACK消息的能力，这一方面会降低正常用户的连接成功率，另一方面会导致某些情况下正常通信的双方会对连接是否成功打开产生误解，如A发给B的第三次握手消息(ACK)半路遗失，A认为连接成功了，B认为没收到ACK，连接没成功，这种情况就需要上层应用采取策略特别处理了。 当然，所有这些方案都不完美各有利弊，最终的策略可能是几种方案的结合使用，形成防御体系，将攻击提前化解在局部，不至于影响整个系统。 DDos攻击的原理介绍一下 listen有一个队列，处理连接请求。在收到匿名IP发过来的SYN之后，会在listen队列中存放一个记录，但是队列容量是有限的，当这样的恶意请求过多的时候，listen队列里就塞满了这些无效的连接请求，然后装不下更多的连接记录了，所以就拒绝其他请求了 长连接、短连接、长轮询、短轮询 所谓短连接，及连接只保持在数据传输过程，请求发起，连接建立，数据返回，连接关闭。它适用于一些实时数据请求，配合轮询来进行新旧数据的更替。短连接的流程就是：建立连接-&gt;发送数据-&gt;断开连接。一次发送之后立即断开连接。所以短连接不用一直占用服务器资源，可以让服务器空出资源来解决其他的连接。 长连接便是在连接发起后，在请求关闭连接前客户端与服务端都保持连接，实质是保持这个通信管道，之后便可以对其进行复用。长连接需要注意的是长连接并不是永久连接的。如果一段时间内，这个连接没有HTTP请求发出的话，那么这个长连接就会被断掉。它适用于涉及消息推送，请求频繁的场景（直播，流媒体）。连接建立后，在该连接下的所有请求都可以重用这个长连接管道，避免了频繁了连接请求，提升了效率。长连接最重要的是可以复用TCP连接，这样减少了每次建立连接和断开连接的开销。所以现在大部分都是长连接，例如一个页面有很多文件，JS文件，CSS文件等等，不能每次都要建立一次连接，所以长连接是比较好的解决办法。 所谓轮询，即是在一个循环周期内不断发起请求来得到数据的机制。只要有请求的地方，都可以实现轮询，譬如各种事件驱动模型。它的长短是在于请求的返回周期。 短轮询指的是在循环周期内，不断发起请求，每一次请求都立即返回结果，根据新旧数据对比决定是否使用这个结果。缺点如下 页面会出现假死：在等到每次 EventLoop 时，都要判断是否到指定时间，直到时间到再执行函数，一旦遇到页面有大量任务或者返回时间特别耗时，页面就会出现假死 无用的网络传输：当客户端按固定频率向服务器发起请求，数据可能并没有更新，浪费服务器资源。 长轮询即是在请求的过程中，若是服务器端数据并没有更新，那么则将这个连接挂起，直到服务器推送新的数据，再返回，然后进入循环周期。客户端像传统轮询一样从服务端请求数据，服务端会阻塞请求不会立刻返回，直到有数据或超时才返回给客户端，然后关闭连接，客户端处理完响应信息后再向服务器发送新的请求。长轮询解决了频繁的网络请求浪费服务器的问题，资源可以及时返回给浏览器。缺点如下 保持连接会消耗资源 服务器没有返回有效数据，程序超时 对于客户端来说，不管是长轮询还是短轮询，客户端的动作都是一样的，就是不停的去请求，不同的是服务端，短轮询情况下服务端每次请求不管有没有变化都会立即返回结果，而长轮询情况下，如果有变化才会立即返回结果，而没有变化的话，则不会再立即给客户端返回结果，直到超时为止。这样一来，客户端的请求次数将会大量减少。但是长轮询也是有坏处的，因为把请求挂起同样会导致资源的浪费，假设还是1000个人停留在某个商品详情页面，那就很有可能服务器这边挂着1000个线程，在不停检测库存量，这依然是有问题的。从这里可以看出，不管是长轮询还是短轮询，都不太适用于客户端数量太多的情况，因为每个服务器所能承载的TCP连接数是有上限的，这种轮询很容易把连接数顶满。 了解TCP连接的11种状态变迁 连接 全部11种状态 客户端独有的：（1）SYN_SENT （2）FIN_WAIT1 （3）FIN_WAIT2 （4）CLOSING （5）TIME_WAIT 。 服务器独有的：（1）LISTEN （2）SYN_RCVD （3）CLOSE_WAIT （4）LAST_ACK 。 共有的：（1）CLOSED （2）ESTABLISHED 。 状态变迁 一开始，建立连接之前服务器和客户端的状态都为CLOSED。服务器创建socket后开始监听，变为LISTEN状态。客户端请求建立连接，向服务器发送SYN报文，客户端的状态变为SYN_SENT。服务器收到客户端的报文后向客户端发送ACK和SYN报文，此时服务器的状态变为SYN_RCVD。然后，客户端收到ACK、SYN，就向服务器发送ACK，客户端状态变为ESTABLISHED，服务器收到客户端的ACK后也变为ESTABLISHED。此时，3次握手完成，连接建立 一个完整的http过程是怎样的？或浏览器输入 www.qq.com 发生了什么，第二次访问与第一次有什么区别吗 对网址进行DNS域名解析，得到对应的IP地址 根据这个IP，找到对应的服务器，发起TCP的三次握手 建立TCP连接后发起HTTP请求 服务器响应HTTP请求，浏览器得到html代码 浏览器解析html代码，并请求html代码中的资源（如js、css图片等）（先得到html代码，才能去找这些资源） 浏览器对页面进行渲染呈现给用户 http有什么缺点、https的过程，https的过程中是否会有安全隐患。说下https解决了什么问题，怎么解决的？说下https的握手过程。 http的缺点 容易被监听：http通信都是明文，数据在客户端与服务器通信过程中，任何一点都可能被劫持。比如，发送了银行卡号和密码，hacker劫取到数据，就能看到卡号和密码，这是很危险的 被伪装：http通信时，无法保证通行双方是合法的，通信方可能是伪装的。比如你请求你怎么知道返回的数据就是来自淘宝，中间人可能返回数据伪装成淘宝。 被篡改：hacker中间篡改数据后，接收方并不知道数据已经被更改 https很好的解决了http的三个缺点（被监听、被篡改、被伪装），https不是一种新的协议，它是http+SSL(TLS)的结合体，SSL是一种独立协议，所以其它协议比如smtp等也可以跟ssl结合。https改变了通信方式，它由以前的http—–&gt;tcp，改为http——&gt;SSL—–&gt;tcp；https采用了共享密钥加密+公开密钥加密的方式 防监听：数据是加密的，所以监听得到的数据是密文 防伪装：伪装分为客户端伪装和服务器伪装，通信双方携带证书，证书相当于身份证，有证书就认为合法，没有证书就认为非法，证书由第三方颁布，很难伪造 防篡改：https对数据做了摘要，篡改数据会被感知到。hacker即使从中改了数据也白搭。 https过程 客户端发送请求到服务器端 服务器端返回证书和公开密钥，公开密钥作为证书的一部分而存在 客户端验证证书和公开密钥的有效性，如果有效，则生成共享密钥并使用公开密钥加密发送到服务器端 服务器端使用私有密钥解密数据，并使用收到的共享密钥加密数据，发送到客户端 客户端使用共享密钥解密数据 SSL加密连接建立 HTTP请求报文和响应报文的格式和内容（HTTP报文的4要素、常见的请求首部和响应首部），说出http有哪些请求方法：PUT,DELETE,POST,GET,HEAD,TRACE的区别（前4个对应增删改查，重点掌握GET和POST的区别） 一个HTTP请求报文由四个部分组成：请求行、请求头部、空行、请求数据。 请求行：请求行由请求方法字段、URL字段和HTTP协议版本字段3个字段组成，它们用空格分隔。比如 GET /data/info.html HTTP/1.1 请求头部：HTTP客户程序，向服务器发送请求的时候必须指明请求类型(一般是GET或者 POST)。如有必要，客户程序还可以选择发送其他的请求头。大多数请求头并不是必需的，但Content-Length除外。对于POST请求来说 Content-Length必须出现。 空行：它的作用是通过一个空行，告诉服务器请求头部到此为止。 请求数据：若方法字段是POST,则通常来说此处放置的就是要提交的数据 http 100 206 是什么。。304是什么(文件未变化，客户端缓冲的文件可以继续使用)？取缓存？好说一下过程，然后讲一下304中xxxxx的header有什么作用。http2.0了解吗？做了什么优化处理 http状态 WebSocket是怎么建立连接的 cookie的作用 Cookie是由HTTP服务器设置的，保存在浏览器中，但HTTP协议是一种无状态协议，在数据交换完毕后，服务器端和客户端的链接就会关闭，每次交换数据都需要建立新的链接。就像我们去超市买东西，没有积分卡的情况下，我们买完东西之后，超市没有我们的任何消费信息，但我们办了积分卡之后，超市就有了我们的消费信息。cookie就像是积分卡，可以保存积分，商品就是我们的信息，超市的系统就像服务器后台，http协议就是交易的过程。 session机制采用的是在服务器端保持状态的方案，而cookie机制则是在客户端保持状态的方案，cookie又叫会话跟踪机制。打开一次浏览器到关闭浏览器算是一次会话。说到这里，讲下HTTP协议，前面提到，HTTP协议是一种无状态协议，在数据交换完毕后，服务器端和客户端的链接就会关闭，每次交换数据都需要建立新的链接。此时，服务器无法从链接上跟踪会话。cookie可以跟踪会话，弥补HTTP无状态协议的不足。 cookie分为会话cookie和持久cookie，会话cookie是指在不设定它的生命周期expires时的状态，前面说了，浏览器的开启到关闭就是一次会话，当关闭浏览器时，会话cookie就会跟随浏览器而销毁。当关闭一个页面时，不影响会话cookie的销毁。会话cookie就像我们没有办理积分卡时，单一的买卖过程，离开之后，信息则销毁。 持久cookie则是设定了它的生命周期expires，此时，cookie像商品一样，有个保质期，关闭浏览器之后，它不会销毁，直到设定的过期时间。对于持久cookie，可以在同一个浏览器中传递数据，比如，你在打开一个淘宝页面登陆后，你在点开一个商品页面，依然是登录状态，即便你关闭了浏览器，再次开启浏览器，依然会是登录状态。这就是因为cookie自动将数据传送到服务器端，在反馈回来的结果。持久cookie就像是我们办理了一张积分卡，即便离开，信息一直保留，直到时间到期，信息销毁。 nginx 网站多用户访问时会出现什么问题？如何优化？ 网络编程服务器端的接口调用顺序 NIO和BIO之类的了解吗？五种I/O模型：1)阻塞I/O2)非阻塞I/O3)I/O复用(select和poll)4)信号驱动I/O（SIGIO）5)异步I/O 怎么理解阻塞I/O 假设有一个管道，线程A从管道中写数据，线程B向管道中写数据。首先讨论缓冲区的概念，缓冲区的引入是为了减少频繁I/O操作而引起频繁的系统调用（它很慢的），当你操作一个流时，更多的是以缓冲区为单位进行操作，这是相对于用户空间而言。对于内核来说，也需要缓冲区。缓冲区满之后，产生I/O事件，告诉线程B去读缓冲区，同时线程A阻塞。缓冲区空之后，产生I/O事件，告诉线程A去写缓冲区，同时线程B阻塞。在阻塞模式下，一个线程只能处理一个I/O事件。 服务器网络编程的代码大致流程 对于socket编程，accept方法是干什么的，在三次握手中属于第几次，可以猜一下，为什么这么觉得。 在 socket 编程中，服务端调用了 bind listen 但是没有调用 accept ，而是调用了 sleep(1000) ，然后客户端 调用 connect 向已经 sleep 的服务端发起请求，问这个 connect 会不会返回。我回答会醒过来，面试官继续问，如果醒过来后，服务端没有写 accept ，那么 connect 会不会返回。 怎么样设计一个比较好的函数完全读出一个socket的所有数据 connect 在 TCP 握手的哪个阶段会返回，是三次握手完成后还是在中间某个阶段返回 backlog的作用，编程中应该设置为多大 创建一个 socket 并且加入到 epoll 中，现在把这个 socket 给 close 掉，那么这个被 close 的 socket 还在不在 epoll 中（没有主动调用 epoll_ctl 去删除），如果这时用 epoll_ctl 去删除它，还能不能删除掉。 TIME_WAIT的话那你来解释一下它的作用吧（两个），如何避免（socket选项和线程池） 假设现在系统中有很多处于TIME_WAIT的连接，这个时候你会怎么做（有一个socket选项，可以进行地址重用，我们可以可重用这些处于TIME_WAIT状态的连接的地址，没有问题的） 假设现在网络延迟很高，但是又没有发生丢包，这个时候用tcp进行传输你觉得速率怎么样？如何解决？（如果网络延迟很高，但是实际上网络没有发生丢包的话，tcp的拥塞控制可能会进行快重传使发送速率下降。从应用层封装udp协议或者使用raw socket直接封装ip数据报） FTP服务器怎么实现(因为自己有写过)，多线程磁盘读写效率（由于磁盘寻道随机性增加而导致I/O效率呈线性下降），是否考虑到断点续传。为什么要用epoll，优缺点是什么，epoll的两种方式，各有什么不同。","categories":[],"tags":[]},{"title":"","slug":"os","date":"2021-03-25T10:21:11.043Z","updated":"2021-03-25T10:21:11.043Z","comments":true,"path":"2021/03/25/os/","link":"","permalink":"http://example.com/2021/03/25/os/","excerpt":"","text":"腾讯后台开发 操作系统 说说进程/线程/协程 进程是资源（CPU、内存等）分配的基本单位，它是程序执行时的一个实例。程序运行时系统就会创建一个进程，并为它分配资源，然后把该进程放入进程就绪队列，进程调度器选中它的时候就会为它分配CPU时间，程序开始真正运行。每个进程都有自己的独立内存空间，不同进程通过进程间通信来通信。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。 线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位。同一进程中的多个线程共享代码段(代码和常量)，数据段(全局变量和静态变量)，扩展段(堆存储)。但是每个线程拥有自己的栈段，栈段又叫运行时段，用来存放所有局部变量和临时变量，即每个线程都有自己的堆栈和局部变量。线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。线程在执行过程中，需要协作同步。不同进程的线程间要利用消息通信的办法实现同步。 协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。 进程和线程的区别： 地址空间:线程是进程内的一个执行单元，进程内至少有一个线程，它们共享进程的地址空间，而进程有自己独立的地址空间 资源拥有:进程是资源分配和拥有的单位,同一个进程内的线程共享进程的资源 线程是处理器调度的基本单位,但进程不是 二者均可并发执行 每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口，但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制 线程与协程的区别： 一个线程可以多个协程，一个进程也可以单独拥有多个协程，这样python中则能使用多核CPU。 线程进程都是同步机制，而协程则是异步 协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态 https://blog.csdn.net/kowzb/article/details/77160249 并发和并行的区别 并发和并行是两种不同的概念。并行意味着程序在任意时刻都是同时运行的，并发意味着程序在单位时间内是同时运行的。并行就是在任一粒度时间内都具备同时执行的能力，最简单的并行就是多机，多台机器并行处理。SMP表面上看是并行的，但由于是共享内存，以及线程间的同步等，不可能完全做到并行。并发是在规定时间内多个请求都得到执行和处理，强调的是给外界的感觉，实际上内部可能是分时操作的。并发重在避免阻塞，使程序不会因为一个阻塞而停职处理。并发典型的应用场景：分时操作系统就是一种并发设计(忽略多核CPU)。 linux下创建进程的方法 linux下，创建进程主要是fork(), vfork(), clone()这三个函数。在linux源码中，这三个调用的执行过程是执行fork(),vfork(),clone()时，通过一个系统调用表映射到sys_fork(),sys_vfork(),sys_clone(),再在这三个函数中去调用do_fork()去做具体的创建进程工作。 fork创建一个进程时，子进程只是完全复制父进程的资源，复制出来的子进程有自己的task_struct结构和pid，但却复制父进程其它所有的资源。这样看来，fork是一个开销十分大的系统调用，这些开销并不是所有的情况下都是必须的。但由于现在Linux中是采取了copy-on-write(写时复制)技术，为了降低开销，fork最初并不会真的产生两个不同的拷贝，因为在那个时候，大量的数据其实完全是一样的。写时复制是在推迟真正的数据拷贝。若后来确实发生了写入，那意味着parent和child的数据不一致了，于是产生复制动作，每个进程拿到属于自己的那一份，这样就可以降低系统调用的开销。所以有了写时复制后呢，vfork其实现意义就不大了。 fork()调用执行一次返回两个值，对于父进程，fork函数返回子程序的进程号，而对于子程序，fork函数则返回零，这就是一个函数返回两次的本质。 在fork之后，子进程和父进程都会继续执行fork调用之后的指令。子进程是父进程的副本。它将获得父进程的数据空间，堆和栈的副本，这些都是副本，父子进程并不共享这部分的内存。也就是说，子进程对父进程中的同名变量进行修改并不会影响其在父进程中的值。但是父子进程又共享一些东西，简单说来就是程序的正文段。正文段存放着由cpu执行的机器指令，通常是read-only的。 vfork系统调用不同于fork，用vfork创建的子进程与父进程共享地址空间，也就是说子进程完全运行在父进程的地址空间上，如果这时子进程修改了某个变量，这将影响到父进程。 有一点要注意的是用vfork()创建的子进程必须显示调用exit()来结束，否则子进程将不能结束，而fork()则不存在这个情况。 Vfork也是在父进程中返回子进程的进程号，在子进程中返回0。用 vfork创建子进程后，父进程会被阻塞直到子进程调用exec或exit。vfork的好处是在子进程被创建后往往仅仅是为了调用exec执行另一个程序，因为它就不会对父进程的地址空间有任何引用，所以对地址空间的复制是多余的 ，因此通过vfork共享内存可以减少不必要的开销。 系统调用fork()和vfork()是无参数的，而clone()则带有参数。fork()是全部复制，vfork()是共享内存，而clone() 是则可以将父进程资源有选择地复制给子进程，而没有复制的数据结构则通过指针的复制让子进程共享，具体要复制哪些资源给子进程，由参数列表中的 clone_flags来决定。另外，clone()返回的是子进程的pid。 介绍一下fork的流程（从源码来看，fork就是简单的把父进程的几乎所有东西都拷贝一份，比如会复制父进程的地址空间、已打开文件描述符、命名空间啊这些之类的…然后修改一些标志让自己与父进程变得不一样，栈和堆会拷贝吗，会，复制之前会做些什么呢？task_struct吗？对对对，在这之前会先从slab中分配一个PCB…FIXME：copy-on-write没有表达出来） 介绍一下fork、vfork还有clone的区别（从源码来分析，它们都用来创建linux轻量级进程的，vfork与fork的区别是，vfork共享父进程的地址空间，vfork之后父进程会让子进程先运行，因为vfork主要用于为了让子进程exec，exec之后子进程会用新程序的数据将内存重新刷一遍，这样它就有了自己的地址空间。子进程exec之后，会向父进程发送信号，这个时候父进程就可以开始运行了，如果子进程修改了父进程地址空间的话，父进程唤醒的时候就会发现自己的数据被改了，完整性丢失，所以这是不安全的。clone的话呢，它提供选项，让你自己选择每次复制哪些东西，但是它调用的还是do_fork好像） 从执行顺序上看，fork不对父子进程的执行次序进行任何限制，fork返回后，子进程和父进程都从调用fork函数的下一条语句开始行，但父子进程运行顺序是不定的，它取决于内核的调度算法；而在vfork调用中，子进程先运行，父进程挂起，直到子进程调用了exec或exit之后，父子进程的执行次序才不再有限制；clone中由标志CLONE_VFORK来决定子进程在执行时父进程是阻塞还是运行，若没有设置该标志，则父子进程同时运行，设置了该标志，则父进程挂起，直到子进程结束为止。 多进程与多线程的区别 多进程优点 更强的容错性：比起多线程的一个好处是一个进程崩溃了不会影响其他进程。 编程相对容易；通常不需要考虑锁和同步资源的问题。 有内核保证的隔离：数据和错误隔离。 对于使用如C/C++这些语言编写的本地代码，错误隔离是非常有用的：采用多进程架构的程序一般可以做到一定程度的自恢复；（master守护进程监控所有worker进程，发现进程挂掉后将其重启）。 多进程缺点 逻辑控制复杂，需要和主程序交互 需要跨进程边界，如果有大数据量传送，就不太好，适合小数据量传送、密集运算 多进程调度开销比较大 多线程优点 无需跨进程边界 程序逻辑和控制方式简单 所有线程可以直接共享内存和变量等 线程方式消耗的总资源比进程方式好 多线程缺点 每个线程与主程序共用地址空间，受限于2GB地址空间 线程之间的同步和加锁控制比较麻烦 一个线程的崩溃可能影响到整个程序的稳定性 线程能够提高的总性能有限，而且线程多了之后，线程本身的调度也是一个麻烦事儿，需要消耗较多的CPU C++ 创建线程 主要是用POSIX那套，pthread_create 读者－写者问题 在系统中，一个数据集(如文件或记录) 被几个并发进程共享，这些线程分两类，一部分只要求进行读操作，称之为“读者”； 另一类要求写或修改操作，我们称之为“写者“。一般而言，对一个数据集，为了保证数据的完整性、正确性，允许多个读者进程同时访问，但是不允许一个写者进程同其它任何一个进程（读者或者写者）同时访问，而这类问题就称之为”读者-写者”问题。 读者优先的算法在操作系统相关的书籍中都有介绍，这是一种最简单的解决办法： 当没有写进程正在访问共享数据集时，读进程可以进入访问，否则必须等待。而读者优先的算法存在”饿死写者”线程的问题：只要有读者不断到来，写者就要持久地等待，直到所有的读者都读完且没有新的读者到来时写者才能写数据集。而在很多情况下我们需要避免”饿死写者”，故而采用写者优先算法 写者优先算法中，1.要让读者与写者之间、以及写者与写者之问要互斥地访同数据集； 2.在无写进程到来时各读者可同时访问数据集； 3.在读者和写者都等待时访问时写者优先 在实现写者优先时，增加一个互斥量，用于写者优先。当有写者来时，就不在允许读者去读取数据， 等待正在读数据的读者完成以后开始写数据，以此实现写者优先。 生产者消费者问题 也称有限缓冲问题，是一个多线程同步问题的经典案例。该问题描述了共享固定大小缓冲区的两个线程——即所谓的“生产者”和“消费者”——在实际运行时会发生的问题。生产者的主要作用是生成一定量的数据放到缓冲区中，然后重复此过程。与此同时，消费者也在缓冲区消耗这些数据。该问题的关键就是要保证生产者不会在缓冲区满时加入数据，消费者也不会在缓冲区中空时消耗数据。 要解决该问题，就必须让生产者在缓冲区满时休眠（要么干脆就放弃数据），等到下次消费者消耗缓冲区中的数据的时候，生产者才能被唤醒，开始往缓冲区添加数据。同样，也可以让消费者在缓冲区空时进入休眠，等到生产者往缓冲区添加数据之后，再唤醒消费者。通常采用进程间通信的方法解决该问题。如果解决方法不够完善，则容易出现死锁的情况。出现死锁时，两个线程都会陷入休眠，等待对方唤醒自己。该问题也能被推广到多个生产者和消费者的情形。 需要保持线程间的同步，即一个线程消费（或生产）完，其他线程才能进行竞争CPU，获得消费（或生产）的机会。对于这一点，可以使用条件变量进行线程间的同步：生产者线程在product之前，需要wait直至获取自己所需的信号量之后，才会进行product的操作；同样，对于消费者线程，在consume之前需要wait直到没有线程在访问共享区（缓冲区），再进行consume的操作，之后再解锁并唤醒其他可用阻塞线程。 在访问共享区资源时，为避免多个线程同时访问资源造成混乱，需要对共享资源加锁，从而保证某一时刻只有一个线程在访问共享资源。 哲学家就餐问题 5个哲学家围坐在桌子周围，每人左边一根筷子，共5根筷子，平时在思考，吃饭时，只有同时拿起左、右2根筷子的哲学家才可以就餐，吃完饭，放下筷子。一般情况下没有问题，但在竟态情况下，比如，每个人只能竞争到左边或右边的一根筷子时，都不能得到2根筷子，就出现了都不能吃饭问题。 线程安全吗？ 通常讲的是针对方法或者函数，在函数执行过程中不会造成资源冲突就是线程安全的,多个线程来调用也没事情，线程不安全就会造成数据错误或者崩溃啊啥的。 线程安全: 在多线程中使用时,不用自已做同步处理. 线程不安全: 在多线程中使用时, 必须做线程同步,不然会有未知后果. 对于线程不安全的代码, 注意做好互斥与同步, 对于异常处理要完善. 如果调用某个接口时需要我们自己采取同步措施来保护该接口访问的共享资源,则这样的接口不是线程安全的. MFC和STL都不是线程安全的. 如果接口中访问的数据都属于私有数据,那么这样的接口是线程安全的.或者几个接口对共享数据都是只读操作,那么这样的接口也是线程安全的.如果多个接口之间有共享数据,而且有读有写的话,如果设计者自己采取了同步措施，调用者不需要考虑数据同步问题，则这样的接口是线程安全的，否则不是线程安全的。 操作系统的进程调度策略 先来先服务调度算法：先来先服务(FCFS)调度算法是一种最简单的调度算法，该算法既可用于作业调度，也可用于进程调度。当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。在进程调度中采用FCFS算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。 短作业(进程)优先调度算法：短作业(进程)优先调度算法SJ(P)F，是指对短作业或短进程优先调度的算法。它们可以分别用于作业调度和进程调度。短作业优先(SJF)的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。而短进程优先(SPF)调度算法则是从就绪队列中选出一个估计运行时间最短的进程，将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重新调度。 高优先权优先调度算法：为了照顾紧迫型作业，使之在进入系统后便获得优先处理，引入了最高优先权优先(FPF)调度算法。此算法常被用于批处理系统中，作为作业调度算法，也作为多种操作系统中的进程调度算法，还可用于实时系统中。当把该算法用于作业调度时，系统将从后备队列中选择若干个优先权最高的作业装入内存。当用于进程调度时，该算法是把处理机分配给就绪队列中优先权最高的进程，这时，又可进一步把该算法分成如下两种。 非抢占式优先权算法：在这种方式下，系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，系统方可再将处理机重新分配给另一优先权最高的进程。这种调度算法主要用于批处理系统中；也可用于某些对实时性要求不严的实时系统中。 抢占式优先权调度算法：在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。因此，在采用这种调度算法时，是每当系统中出现一个新的就绪进程i 时，就将其优先权Pi与正在执行的进程j 的优先权Pj进行比较。如果Pi≤Pj，原进程Pj便继续执行；但如果是Pi&gt;Pj，则立即停止Pj的执行，做进程切换，使i 进程投入执行。显然，这种抢占式的优先权调度算法能更好地满足紧迫作业的要求，故而常用于要求比较严格的实时系统中，以及对性能要求较高的批处理和分时系统中。 容易出现优先级倒置现象：优先级反转是指一个低优先级的任务持有一个被高优先级任务所需要的共享资源。高优先任务由于因资源缺乏而处于受阻状态，一直等到低优先级任务释放资源为止。而低优先级获得的CPU时间少，如果此时有优先级处于两者之间的任务，并且不需要那个共享资源，则该中优先级的任务反而超过这两个任务而获得CPU时间。如果高优先级等待资源时不是阻塞等待，而是忙循环，则可能永远无法获得资源，因为此时低优先级进程无法与高优先级进程争夺CPU时间，从而无法执行，进而无法释放资源，造成的后果就是高优先级任务无法获得资源而继续推进。 高响应比优先调度算法：在批处理系统中，短作业优先算法是一种比较好的算法，其主要的不足之处是长作业的运行得不到保证。如果我们能为每个作业引入前面所述的动态优先权，并使作业的优先级随着等待时间的增加而以速率a 提高，则长作业在等待一定的时间后，必然有机会分配到处理机。在利用该算法时，每要进行调度之前，都须先做响应比的计算，这会增加系统开销。 时间片轮转法：在早期的时间片轮转法中，系统将所有的就绪进程按先来先服务的原则排成一个队列，每次调度时，把CPU分配给队首进程，并令其执行一个时间片。时间片的大小从几ms 到几百ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程在一给定的时间内均能获得一时间片的处理机执行时间。换言之，系统能在给定的时间内响应所有用户的请求。 多级反馈队列调度算法：前面介绍的各种用作进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程，而且如果并未指明进程的长度，则短进程优先和基于进程长度的抢占式调度算法都将无法使用。而多级反馈队列调度算法则不必事先知道各种进程所需的执行时间，而且还可以满足各种类型进程的需要，因而它是目前被公认的一种较好的进程调度算法。在采用多级反馈队列调度算法的系统中，调度算法的实施过程如下所述。 应设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，第二个队列次之，其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片的大小也各不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。例如，第二个队列的时间片要比第一个队列的时间片长一倍，……，第i+1个队列的时间片要比第i个队列的时间片长一倍。 当一个新进程进入内存后，首先将它放入第一队列的末尾，按FCFS原则排队等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按FCFS原则等待调度执行；如果它在第二队列中运行一个时间片后仍未完成，再依次将它放入第三队列，……，如此下去，当一个长作业(进程)从第一队列依次降到第n队列后，在第n 队列便采取按时间片轮转的方式运行。 仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第1～(i-1)队列均空时，才会调度第i队列中的进程运行。如果处理机正在第i队列中为某进程服务时，又有新进程进入优先权较高的队列(第1～(i-1)中的任何一个队列)，则此时新进程将抢占正在运行进程的处理机，即由调度程序把正在运行的进程放回到第i队列的末尾，把处理机分配给新到的高优先权进程。 批处理系统常用调度算法：FCFS、短作业优先、最短剩余时间优先、高响应比优先 分时系统调度算法：轮转调度、优先级调度多级队列调度、彩票调度 实时系统：单比率调度、限期调度、最少裕度法 堆是线程共有还是私有，堆是进程共有还是私有，栈呢 在多线程环境下，每个线程拥有一个栈和一个程序计数器。栈和程序计数器用来保存线程的执行历史和线程的执行状态，是线程私有的资源。其他的资源（比如堆、地址空间、全局变量）是由同一个进程内的多个线程共享。 如何安全的析构线程 作为 class 数据成员的 Mutex 只能用于同步本 class 的其他数据成员的读和写，它不能保护安全地析构。因为成员 mutex 的生命期最多与对象一样长，而析构动作可说是发生在对象身故之后（或者身亡之时）。另外，对于基类对象，那么调用到基类析构函数的时候，派生类对象的那部分已经析构了，那么基类对象拥有的 mutex 不能保护整个析构过程。再说，析构过程本来也不需要保护，因为只有别的线程都访问不到这个对象时，析构才是安全的。 正确做法是使用shared_ptr。shared_ptr控制对象的生命期。shared_ptr 是强引用（想象成用铁丝绑住堆上的对象），只要有一个指向 x 对象的 shared_ptr 存在，该 x 对象就不会析构。当指向对象 x 的最后一个 shared_ptr 析构或 reset 的时候，x 保证会被销毁。weak_ptr不控制对象的生命期，但是它知道对象是否还活着（想象成用棉线轻轻拴住堆上的对象）。如果对象还活着，那么它可以提升 (promote) 为有效的 shared_ptr；如果对象已经死了，提升会失败，返回一个空的 shared_ptr。shared_ptr/weak_ptr 的“计数”在主流平台上是原子操作，没有用锁，性能不俗。 多进程、多线程的使用场景 多进程 nginx主流的工作模式是多进程模式 几乎所有的web server服务器服务都有多进程的，至少有一个守护进程配合一个worker进程，例如apached,httpd等等以d结尾的进程包括init.d本身就是0级总进程，所有你认知的进程都是它的子进程 chrome浏览器也是多进程方式 redis也可以归类到“多进程单线程”模型 多线程 线程间有数据共享，并且数据是需要修改的 提供非均质的服务（有优先级任务处理）事件响应有优先级 单任务并行计算，在非CPU Bound的场景下提高响应速度，降低时延 与人有IO交互的应用，良好的用户体验（键盘鼠标的输入，立刻响应） 如何选择 需要频繁创建销毁的优先用线程（进程的创建和销毁开销过大） 需要进行大量计算的优先使用线程（CPU频繁切换） 强相关的处理用线程，弱相关的处理用进程 可能要扩展到多机分布的用进程，多核分布的用线程 一个进程三个线程与三个进程的区别，优劣。 前者轻，省空间；后者重，占用空间大 前者鲁棒性弱，后者鲁棒性强 前者上下文切换代价小，后者大 前者可以通过共享内存通信，后者不行 多线程会有什么问题？ 原子性问题 所谓原子性，指的是一个操作不可中断，即在多线程并发的环境下，一个操作一旦开始，就会在同一个CPU时间片内执行完毕。如果同一个线程的多个操作在不同的CPU时间片上执行，由于中间出现停滞，后面的操作在执行时可能某个共享数据被其他线程修改，而该修改并未同步到当前线程中，导致当前线程操作的数据与实际不符，这种由于执行不连贯导致的数据不一致问题被称作原子性问题。 可见性问题 可见性问题的出现与线程访问共享数据的方式有关。线程访问堆（方法区）中的变量时，先在栈中建立一个变量的副本，修改后再同步到堆中。如果一个线程刚建立副本，这时另一线程修改了变量，尚未同步到堆中，这时就会出现两个线程操作同一变量的同一种状态的现象 有序性问题 为了提高执行效率，CPU会对那些没有依赖关系的指令重新排序，重新排序后的执行结果与顺序执行结果相同。指令重排在单线程环境下是安全的，在多线程环境下就可能出现问题。 put的时候如果扩容，会导致形成循环链表，这样get的时候就会陷入死循环。还有大部分并发都存在的问题吧，临界区资源没有上锁会导致脏读、丢失更新什么的。就两个线程同时put同一个key，那有一个线程的value就丢失更新了。或者某个线程同时get了某个key，这个key又被其他线程修改了，脏读了。 僵尸进程 在Linux系统中，任何一个子进程在调用exit()函数结束运行后,内核会释放该进程的所有资源，包括占用的内存和打开的文件等。 同时，也会留下一个叫做僵尸进程（Zombie）的数据结构，Zombie中存储了该进程的进程号、退出码、退出状态、使用的CPU时间等信息。即僵尸进程是早已死亡的子进程，但在进程表中占了一个位置（slot）。 子进程还会向父进程发送SIGCHLD信号，父进程调用wait()或者waitpid()函数可以将僵尸进程释放（为它收尸）。若父进程在没有释放掉僵尸进程就提前结束了，僵尸进程则会由init进程接管。init进程（PID = 1）会作为它的父进程，为它收尸。但是如果父进程是一个循环，不会结束，却又没有为SIGCHLD信号绑定处理函数，或者没有调用wait()/waitpid()函数为僵尸进程收尸，则该僵尸进程会一直在系统中存在。 僵尸进程的危害 如果系统中存在很多僵尸进程，进程号会被它们一直占用。这时，有限的进程号将会耗尽，使得系统无法创建新的进程。 怎么看僵尸进程 ps -ef | grep defunct 怎么避免僵尸进程 父进程收到SIGCHLD信号后，调用wait()或者waitpid()函数释放僵尸进程。但是，这样会导致父进程挂起。 如果父进程很忙，可以使用signal函数为SIGCHLD信号安装handler，handler中会调用wait函数回收僵尸进程。子进程结束后，父进程收到SIGCHLD信号后会执行handler。 父进程显式地表示自己对子进程的结束不感兴趣 父进程如果不关心子进程什么时候结束，可以通过signal(SIGCLD, SIG_IGN)或者signal(SIGCHLD, SIG_IGN)通知内核，自己对子进程的结束不感兴趣。它们的区别是SIGCLD在安装完信号处理函数的时候还会检查是否已经存在结束的子进程，如果有就调用信号处理函数，而SIGCHLD不会，也就是可能会丢掉已经有子进程已经结束这个事实 子进程结束后，内核会释放僵尸进程，并不在给父进程发送信号 孤儿进程 orphan 父进程退出，而它的一个或多个子进程还在运行，这些子进程将成为孤儿进程（orphan process）。 孤儿进程将会被init进程收养，并由init进程完成对它们的状态收集工作。 由于孤儿进程会被init进程收养，因此孤儿进程调用exit()结束运行时，也会由init进程完成回收工作，而不会对系统造成危害。 守护进程 daemon 是运行在后台的一种特殊进程，独立于控制终端，并且周期性的执行某种任务或者等待处理某些发生的事件。 守护进程不需要用户输入就能运行，它可以提供某种服务。并且不是对系统提供服务，就是对某个应用程序提供服务。 守护进程一般在系统启动时就开启了，除非强制终止，否则直到系统关机都保持运行。 守护进程的父进程是init进程： 创建守护进程时，父进程在fork出子进程后就提前结束运行了。守护进程将会变成孤儿进程，由init进程收养。 守护进程是非交互式程序，没有控制终端，无论是标准输出设备stdout还是标准出错设备stderr的输出都需要进行特殊处理。 守护进程的名称通常以d结尾，如sshd、xinetd、crond等。 死锁产生原因、避免、检测与解决 所谓死锁，是指多个进程在运行过程中因争夺资源而造成的一种僵局，当进程处于这种僵持状态时，若无外力作用，它们都将无法再向前推进。 产生死锁的原因 资源竞争。系统资源分为可剥夺和不可剥夺，产生死锁中的竞争资源之一指的是竞争不可剥夺资源，另外一种资源指的是竞争临时资源（临时资源包括硬件中断、信号、消息、缓冲区内的消息等），通常消息通信顺序进行不当，则会产生死锁 进程间推进顺序非法 产生死锁的必要条件 互斥条件：进程要求对所分配的资源进行排它性控制，即在一段时间内某资源仅为一进程所占用 请求和保持条件：当进程因请求资源而阻塞时，对已获得的资源保持不放 不可剥夺条件：进程已获得的资源在未使用完之前，不能剥夺，只能在使用完时由自己释放 环路等待条件：在发生死锁时，必然存在一个进程–资源的环形链 预防死锁 资源一次性分配：一次性分配所有资源，这样就不会再有请求了 只要有一个资源得不到分配，也不给这个进程分配其他的资源 可剥夺资源：即当某进程获得了部分资源，但得不到其它资源，则释放已占有的资源 资源有序分配法：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反 避免死锁 预防死锁的几种策略，会严重地损害系统性能。因此在避免死锁时，要施加较弱的限制，从而获得较满意的系统性能。由于在避免死锁的策略中，允许进程动态地申请资源。因而系统在进行资源分配之前预先计算资源分配的安全性。若此次分配不会导致系统进入不安全的状态，则将资源分配给进程；否则，进程等待。其中最具有代表性的避免死锁算法是银行家算法。 为实现银行家算法，每一个新进程在进入系统时，必须申明在运行过程中可能需要每种资源类型的最大单元数目，其数目不应超过系统所拥有的资源总量。当进程请求一组资源时，系统必须首先确定是否有足够的资源分配给该进程。若有，再进一步计算在将这些资源分配给进程后，是否会使系统处于不安全状态。如果不会，才将资源分配给它，否则让进程等待。首先为实现银行家算法，在系统中必须设置这样四个数据结构： 可利用资源向量Avaliable。这是一个含有m个元素的数组，其中每一个元素代表一类可利用的资源数目，其初始值是系统所配置的该类全部可用资源的数目，其中的每一个元素代表一类可利用的资源数目，其初始值是系统中所配置的该类全部可用资源的数目，其数值随该类资源的分配和回收而动态的改变。如果Available[j]=K，则表示系统中现有Rj类资源的最大数目为K。 最大需求矩阵Max。是一个n×m的矩阵，定义了系统中n个进程中的每一个进程对m类资源的最大需求。如果Max[i, j]=K，则表示进程i需要Rj类资源的最大数目为K。 分配矩阵Allocation。是一个n×m的矩阵，定义了系统中每一类资源当前已分配给每一进程的资源数。如果Allocation[i, j]=K，则表示进程i当前已分得Rj类资源的数目为K。 需求矩阵Need。是一个n×m的矩阵，用以表示每一个进程尚需的各类资源数。如果Need[i, j]=K，则表示进程i还需要Rj类资源K个方能完成其任务。它们之间的关系为:Need[i, j]=Max[i, j]-Allocation[i, j] 银行家算法描述如下： 设置两个向量 工作向量Work，表示系统可提供给进程继续运行所需的各类资源数目，含有m个元素，在执行安全算法开始时，Work=Available Finish，表示系统是否有足够的资源分配给进程，使之运行完成。先令Finish[i]=false；当有足够资源分配给进程时，令Finish[i]=true 从进程集合中找到一个能满足下述条件的进程： Finish[i]=false Need[i, j]≤Work[j] 若找到，执行下一步，否则执行下下一步 当进程Pi获得资源后，可顺利执行，直至完成，并释放出分配给它的资源，故执行： Work[j]=Work[j]-Allocation[i, j] Finish[i]=true 返回上一步 如果所有进程的Finish[i]=true都满足，则表示系统处于安全状态，否则，系统处于不安全状态 死锁检测 首先为每个进程和每个资源指定一个唯一的号码 然后建立资源分配表和进程等待表 死锁解除 剥夺资源：从其它进程剥夺足够数量的资源给死锁进程，以解除死锁状态 撤消进程：可以直接撤消死锁进程或撤消代价最小的进程，直至有足够的资源可用，死锁状态消除为止；所谓代价是指优先级、运行代价、进程的重要性和价值等 进程上下文切换怎么实现 进行进程切换就是从正在运行的进程中收回处理器，然后再使待运行进程来占用处理器。这里所说的从某个进程收回处理器，实质上就是把进程存放在处理器的寄存器中，从而把处理器的寄存器腾出来让其他进程使用。那么被中止运行进程的中间数据存在何处好呢？当然这个地方应该是进程的私有堆栈。 让进程来占用处理器，实质上是把某个进程存放在私有堆栈中寄存器的数据（前一次本进程被中止时的中间数据）再恢复到处理器的寄存器中去，并把待运行进程的断点送入处理器的程序指针PC，于是待运行进程就开始被处理器运行了，也就是这个进程已经占有处理器的使用权了。 在切换时，一个进程存储在处理器各寄存器中的中间数据叫做进程的上下文，所以进程的切换实质上就是被中止运行进程与待运行进程上下文的切换。在进程未占用处理器时，进程的上下文是存储在进程的私有堆栈中的。 显然，进程的切换可以用中断技术来实现，即当调度器获得了待运行进程的控制块之后，应立即用软中断指令来中止当前进程的运行，并保存当前进程的PC值和PSW值。其后，使用压栈指令把处理器其他寄存器的值压入进程私有堆栈。接下来，就从待运行进程的进程控制块中取出私有堆栈指针的值并存入处理器的寄存器SP，至此SP就指向了待运行进程的私有堆栈，于是下面就自待运行进程的私有堆栈中弹出上下文进入处理器。最后，利用中断返回指令来实现自待运行进程的私有堆栈中弹出PSW值和自待运行进程的 私有堆栈中弹出PC值的功能。 PV操作 PV操作是有名的计算机科学家狄克斯特拉为了解决一类问题而创造的，例如：假如P1和P2是分别将数据送入缓冲B和从缓冲B读出数据的两个进程，为了防止这两个进程并发时产生错误，狄克斯特拉设计了一种同步机制叫“PV操作”。PV操作有P操作和V操作组成，它们是两个不可中断的过程，也叫做原语。它是为了能够实现对于并发进程中临界区的管理要求。 为什么要有PV操作？是为了防止两个进程并发时产生错误。这里不得不说的就是，并发进程之间分为两种，一种就是有交互的，一种是无任何关联的。没有关联的并发进程是相互独立的，谁也不影响谁。但是交互的并发进程可就不一样了，因为他们是共享资源的，一个进程运行时，经常会由于自身或外界的原因而被中端，且断点是不固定的。也就是说进程执行的相对速度不能由进程自己来控制，于是就会导致并发进程在共享资源的时出现与时间有关的错误。 我们把并发进程中与共享变量有关的程序段称为临界区。信号量的值与相应资源的使用情况有关。当它的值大于0时，表示当前可用资源的数量；当它的值小于0时，其绝对值表示等待使用该资源的进程个数。 P操作：将信号量S减去1，若结果小于0，则把调用P（S）的进程置成等待信号量S的状态。即为请求资源。 V操作：将信号量S加上1，若结果不大于0，则释放一个等待信号量S的进程。即为释放资源。 进程间通信 多个进程可以共享系统中的各种资源，但其中许多资源一次只能为一个进程使用，我们把一次仅允许一个进程使用的资源成为临界资源。许多物理设备都属于临界资源，如打印机等。对临界资源的访问，必须互斥的进行，在每个进程中，访问临界资源的那段代码成为临界区（critical section）。 进程间通信和同步有如下目的: 数据传输：一个进程需要将它的数据发送给另一个进程。 共享数据：多个进程想要操作共享数据，一个进程对共享数据的修改，别的进程应该立刻看到 通知事件：一个进程需要向另一个或另一组进程发送消息，通知它（它们）发生了某种事件（如进程终止时要通知父进程） 资源共享：多个进程之间共享相同的资源。为了做到这一点，需要内核提供锁和同步机制 进程控制；有些进程希望完全控制另一个进程的执行（如Degbug进程），此时控制进程希望能够拦截另一个进程的所有陷入和异常，并能够及时知道它的状态变化 通信手段 信号量(semaphore) ：主要作为进程间以及同一进程不同线程之间的同步手段。 共享内存：使得多个进程可以访问同一块内存空间，是最快的IPC形式。是针对其他通信机制运行效率低而设计的。往往与其他通信机制，如信号量结合使用，来达到进程间的同步与互斥。 Message（消息队列）：消息队列是消息的链表，包括Posix消息队列System V消息队列。有足够权限的进程可以向消息队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息少，管道承载无格式字节流以及缓冲区大小受限等缺点。 管道（pipe）与有名管道（named pipe):管道只能在具有公共祖先的两个进程间使用。有名管道克服了管道没有名字的限制，因此，除具有管道所具有的功能外，它还允许无亲缘关系进程间的通信。 信号（signal）：信号时比较复杂的通信方式，用于通知接受进程有关某种事件发生，除了用于进程间通信外，进程还可以发送信号给进程本身。 套接字（Socket）：更为一般的进程间通信机制，可用于不同机器之间的进程间通信.起初是由UNIX系统的BSD分支开发出来的，但现在一般可以移植到其他类unix系统上：Linux和System V的变种都支持套接字。 线程间通信 通信手段 信号量 互斥量 信号量有计数能力，互斥量是信号量的一个简化版本。互斥量是一个处于两个状态之一的变量：解锁和加锁。这样，只需要一个二进制位表示它，不过实际上，常常使用一个整形量，0表示解锁，而其他所有的值则表示加锁。互斥量使用两个过程。当一个线程（或进程）需要访问临界区时，它调用mutex_lock。如果互斥量当前是解锁的（即临界区可用）。此调用成功，调用线程可以进入该临界区。另一方面，如果该互斥量已经加锁，调用线程被阻塞，直到在临界区中的线程完成并调用mutex_unlock。如果多个线程被阻塞在互斥量上，将随机选择一个线程并允许它获得锁。一个线程如果想要进入临界区，它首先尝试锁住相关的互斥量。如果互斥量没有加锁，那么这个进程可以立即进入，并且该互斥量被自动锁住以防止其他线程进入。如果互斥量已经被加锁，则调用线程被阻塞，直到该互斥量被解锁。如果多个线程在等待同一个互斥量，当它被解锁时，这些等待的线程中只有一个被允许运行并将互斥量重新锁定。这些互斥量不是强制的，而是由程序员来保证线程正确地使用它们。 条件变量 条件变量允许一个进程在需要的条件未达到时阻塞自己并在以后被唤醒。POSIX中与条件变量相关的最重要的两个操作是pthread_cond_wait和pthread_cond_signal。前者阻塞调用线程直到另一其他线程向它发信号（使用后一个调用）。当然，阻塞与等待的原因不是等待与发信号协议的一部分。被阻塞的线程经常是在等待发信号的线程去做某些工作、释放某些资源或是进行其他的一些活动。只有完成后被阻塞的线程才可以继续运行。条件变量允许这种等待与阻塞原子性地进行。互斥量和条件变量经常一起使用。这种模式用于让一个线程锁住一个互斥量，然后当它不能获得它期待的结果时等待一个条件变量。最后另一个线程会向他发信号，使它可以继续运行。 共享内存底层是怎么实现的 两个不同进程A、B共享内存的意思是，同一块物理内存被映射到进程A、B各自的进程地址空间。进程A可以即时看到进程B对共享内存中数据的更新，反之亦然。由于多个进程共享同一块内存区域，必然需要某种同步机制，互斥锁和信号量都可以。采用共享内存通信的一个显而易见的好处是效率高，因为进程可以直接读写内存，而不需要任何数据的拷贝。对于像管道和消息队列等通信方式，则需要在内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次数据：一次从输入文件到共享内存区，另一次从共享内存区到输出文件。实际上，进程之间在共享内存时，并不总是读写少量数据后就解除映射，有新的通信时，再重新建立共享内存区域。而是保持共享区域，直到通信完毕为止，这样，数据内容一直保存在共享内存中，并没有写回文件。共享内存中的内容往往是在解除映射时才写回文件的。因此，采用共享内存的通信方式效率是非常高的。 https://blog.csdn.net/Al_xin/article/details/38602093 解释一下内存池的概念 内存池是一种内存分配方式。通常我们习惯直接使用new、malloc等API申请内存，这样做的缺点在于所申请内存块的大小不定，当频繁使用时会造成大量的内存碎片并进而降低性能。 内存池则是在真正使用内存之前，预先申请分配一定数量、大小相等（一般情况下）的内存块留作备用。当有新的内存需求时，就从内存池中分出一部分内存块，若内存块不够再继续申请新的内存。这样做的一个显著优点是，使得内存分配效率得到提升。 应用程序自定义的内存池根据不同的适用场景又有不同的类型。从线程安全的角度来分，内存池可以分为单线程内存池和多线程内存池。单线程内存池整个生命周期只被一个线程使用，因而不需要考虑互斥访问的问题；多线程内存池有可能被多个线程共享，因此需要在每次分配和释放内存时加锁。相对而言，单线程内存池性能更高，而多线程内存池适用范围更加广泛。从内存池可分配内存单元大小来分，可以分为固定内存池和可变内存池。所谓固定内存池是指应用程序每次从内存池中分配出来的内存单元大小事先已经确定，是固定不变的；而可变内存池则每次分配的内存单元大小可以按需变化，应用范围更广，而性能比固定内存池要低。 内存池技术因为其对内存管理有着显著的优点，在各大项目中广泛应用，备受推崇。但是，通用的内存管理机制要考虑很多复杂的具体情况，如多线程安全等，难以对算法做有效的优化，所以，在一些特殊场合，实现特定应用环境的内存池在一定程度上能够提高内存管理的效率。 经典内存池技术，是一种用于分配大量大小相同的小对象的技术。通过该技术可以极大加快内存分配/释放过程。既然是针对特定对象的内存池，所以内存池一般设置为类模板，根据不同的对象来进行实例化。 经典内存池实现过程 先申请一块连续的内存空间，该段内存空间能够容纳一定数量的对象 每个对象连同一个指向下一个对象的指针一起构成一个内存节点（Memory Node）。各个空闲的内存节点通过指针形成一个链表，链表的每一个内存节点都是一块可供分配的内存空间 某个内存节点一旦分配出去，从空闲内存节点链表中去除 一旦释放了某个内存节点的空间，又将该节点重新加入空闲内存节点链表 如果一个内存块的所有内存节点分配完毕，若程序继续申请新的对象空间，则会再次申请一个内存块来容纳新的对象。新申请的内存块会加入内存块链表中 内存池特征 无内存泄漏：正确的使用内存池的申请和释放函数不会造成内存泄露，更重要的是，即使不正确的使用了申请和释放函数，内存池中的内存也会在进程结束时被全部自动释放，不会造成系统的内存泄露。 申请的内存数组没有被填充：例如一个元素的内存大小为A，那么元素数组若包含n个元素，则该数组的内存大小必然是A*n，不会有多余的内存来填充该数组。尽管每个元素也许包含一些填充的东西。 任何数组内存块的位置都和使用operator new[]分配的内存块位置一致，这表明你仍可以使用那些通过数组指针计算内存块位置的算法。 内存池要比直接使用系统的动态内存分配快。这个快是概率意义上的，不是每个时刻，每种内存池都比直接使用new或者malloc快。例如，当程序使用内存池时内存池恰好处于已经满了的状态，那么这次内存申请会导致内存池自我扩充，肯定比直接new一块内存要慢。但在大部分时候，内存池要比new或者malloc快很多。 有哪些内存池 目前我只知道C++有boost内存池，其实是个轮子 早期的内存池技术是为了专门解决那种频繁申请和释放相同大小内存块的程序，因此早期的一些内存池都是用相同大小的内存块链表组织起来的。 Boost的内存池则对内存块的大小是否相同没有限制，因此只要是频繁动态申请释放内存的长时间运行程序，都适用Boost内存池。这样可以有效减少内存碎片并提高程序运行效率。 内存碎片（外碎片和内碎片） 描述一个系统中所有不可用的空闲内存。这些资源之所以仍然未被使用，是因为负责分配内存的分配器使这些内存无法使用。这一问题通常都会发生，原因在于空闲内存以小而不连续方式出现在不同的位置。由于分 配方法决定内存碎片是否是一个问题，因此内存分配器在保证空闲资源可用性方面扮演着重要的角色。 内部碎片是已经被分配出去的的内存空间大于请求所需的内存空间。 外部碎片是指还没有分配出去，但是由于大小太小而无法分配给申请空间的新进程的内存空间空闲块。 固定分区存在内部碎片，可变式分区分配会存在外部碎片 页式虚拟存储系统存在内部碎片；段式虚拟存储系统，存在外部碎片 为了有效的利用内存，使内存产生更少的碎片，要对内存分页，内存以页为单位来使用，最后一页往往装不满，于是形成了内部碎片。 为了共享要分段，在段的换入换出时形成外部碎片，比如5K的段换出后，有一个4k的段进来放到原来5k的地方，于是形成1k的外部碎片。 内存为程序分配空间有四种分配方式 连续分配方式 基本分页存储管理方式 基本分段存储管理方式 段页式存储管理方式 详细 你知道的锁有哪些, 有什么区别。有哪些自旋锁，分别是怎么实现的 互斥锁 互斥锁主要用于实现内核中的互斥访问功能。内核互斥锁是在原子API之上实现的，但这对于内核用户是不可见的。对它的访问必须遵循一些规则：同一时间只能有一个任务持有互斥锁，而且只有这个任务可以对互斥锁进行解锁。互斥锁不能进行递归锁定或解锁。一个互斥锁对象必须通过其API初始化，而不能使用memset或复制初始化。一个任务在持有互斥锁的时候是不能结束的。互斥锁所使用的内存区域是不能被释放的。使用中的互斥锁是不能被重新初始化的。并且互斥锁不能用于中断上下文。但是互斥锁比当前的内核信号量选项更快，并且更加紧凑 信号量 Linux内核的信号量在概念和原理上与用户态的SystemV的IPC机制信号量是一样的，但是它绝不可能在内核之外使用，因此它与SystemV的IPC机制信号量毫不相干。 信号量在创建时需要设置一个初始值，表示同时可以有几个任务可以访问该信号量保护的共享资源，初始值为1就变成互斥锁（Mutex），即同时只能有一个任务可以访问信号量保护的共享资源。一个任务要想访问共享资源，首先必须得到信号量，获取信号量的操作将把信号量的值减1，若当前信号量的值为0，表明无法获得信号量，该任务必须挂起在该信号量的等待队列等待该信号量可用；若当前信号量的值为正数，表示可以获得信号量，因而可以立刻访问被该信号量保护的共享资源。当任务访问完被信号量保护的共享资源后，必须释放信号量，释放信号量通过把信号量的值加1实现，如果信号量的值为非正数，表明有任务等待当前信号量，因此它也唤醒所有等待该信号量的任务。 读写锁。也叫作共享式互斥锁，读写信号量 有3种状态：读模式的加锁状态、写模式的加锁状态、不加锁状态。 写模式加锁状态：在这个锁被解锁之前，所有试图对这个锁加锁的线程都会被阻塞。 读模式加锁状态：所有试图以读模式进行加锁的线程都可以得到访问权，但是任何希望以写模式对此加锁的线程都会阻塞，直到所有的线程释放他们的读锁为止。 顺序锁 跟读写锁很像，用于能够区分读与写的场合，并且是读操作很多、写操作很少，写操作的优先权大于读操作。 seqlock的实现思路是，用一个递增的整型数表示sequence。写操作进入临界区时，sequence++；退出临界区时，sequence再++。写操作还需要获得一个锁（比如mutex），这个锁仅用于写写互斥，以保证同一时间最多只有一个正在进行的写操作。当sequence为奇数时，表示有写操作正在进行，这时读操作要进入临界区需要等待，直到sequence变为偶数。读操作进入临界区时，需要记录下当前sequence的值，等它退出临界区的时候用记录的sequence与当前sequence做比较，不相等则表示在读操作进入临界区期间发生了写操作，这时候读操作读到的东西是无效的，需要返回重试。 seqlock写写是必须要互斥的。但是seqlock的应用场景本身就是读多写少的情况，写冲突的概率是很低的。所以这里的写写互斥基本上不会有什么性能损失。而读写操作是不需要互斥的。seqlock的应用场景是写操作优先于读操作，对于写操作来说，几乎是没有阻塞的（除非发生写写冲突这一小概率事件），只需要做sequence++这一附加动作。而读操作也不需要阻塞，只是当发现读写冲突时需要retry。 自旋锁 与互斥锁有点类似，只是自旋锁不会引起调用者睡眠，如果自旋锁已经被别的执行单元保持，调用者就一直循环在那里看是否该自旋锁的保持者已经释放了锁，”自旋”一词就是因此而得名。 由于自旋锁使用者一般保持锁时间非常短，因此选择自旋而不是睡眠是非常必要的，自旋锁的效率远高于互斥锁。 信号量和读写信号量适合于保持时间较长的情况，它们会导致调用者睡眠，因此只能在进程上下文使用（_trylock的变种能够在中断上下文使用），而自旋锁适合于保持时间非常短的情况，它可以在任何上下文使用。 如果被保护的共享资源只在进程上下文访问，使用信号量保护该共享资源非常合适，如果对共享资源的访问时间非常短，自旋锁也可以。但是如果被保护的共享资源需要在中断上下文访问（包括底半部即中断处理句柄和顶半部即软中断），就必须使用自旋锁。 自旋锁保持期间是抢占失效的，而信号量和读写信号量保持期间是可以被抢占的。自旋锁只有在内核可抢占或SMP的情况下才真正需要，在单CPU且不可抢占的内核下，自旋锁的所有操作都是空操作。 跟互斥锁一样，一个执行单元要想访问被自旋锁保护的共享资源，必须先得到锁，在访问完共享资源后，必须释放锁。如果在获取自旋锁时，没有任何执行单元保持该锁，那么将立即得到锁；如果在获取自旋锁时锁已经有保持者，那么获取锁操作将自旋在那里，直到该自旋锁的保持者释放了锁。 RCU RCU也是用于能够区分读与写的场合，并且也是读多写少，但是读操作的优先权大于写操作（与seqlock相反）。 RCU的实现思路是，读操作不需要互斥、不需要阻塞、也不需要原子指令，直接读就行了。而写操作在进行之前需要把被写的对象copy一份，写完之后再更新回去。其实RCU所能保护的并不是任意的临界区，它只能保护由指针指向的对象（而不保护指针本身）。读操作通过这个指针来访问对象（这个对象就是临界区）；写操作把对象复制一份，然后更新，最后修改指针使其指向新的对象。由于指针总是一个字长的，对它的读写对于CPU来说总是原子的，所以不用担心更新指针只更新到一半就被读取的情况（指针的值为0x11111111，要更新为0x22222222，不会出现类似0x11112222这样的中间状态）。所以，当读写操作同时发生时，读操作要么读到指针的旧值，引用了更新前的对象、要么读到了指针的新值，引用了更新后的对象。即使同时有多个写操作发生也没关系（是否需要写写互斥跟写操作本身的场景相关）。 Linux的虚拟地址空间布局是怎么样的。内存分段机制（代码段、数据段、BSS、堆、栈）以及每个段的作用 虚拟地址通过页表(Page Table)映射到物理内存，页表由操作系统维护并被处理器引用。内核空间在页表中拥有较高特权级，因此用户态程序试图访问这些页时会导致一个页错误(page fault)。在Linux中，内核空间是持续存在的，并且在所有进程中都映射到同样的物理内存。内核代码和数据总是可寻址，随时准备处理中断和系统调用。与此相反，用户模式地址空间的映射随进程切换的发生而不断变化。 分段机制是为了解决冲突问题，它是一种机制，这种机制使得很方便地管理内存 分段是一个逻辑实体。一个段中可以是变量，源代码或者堆栈。一般来说每个段中不会包含不同类型的内容。而分段主要有以下几个作用： 解决编译问题： 前面提到过在编译时地址覆盖的问题，可以通过分段来解决，从而简化编译程序。 重新编译： 因为不同类型的数据在不同的段中，但其中一个段进行修改后，就不需要所有的段都重新进行编译。 内存共享： 对内存分段，可以很容易把其中的代码段或数据段共享给其他程序，分页中因为数据代码混合在一个页面中，所以不便于共享。 安全性： 将内存分为不同的段之后，因为不同段的内容类型不同，所以他们能进行的操作也不同，比如代码段的内容被加载后就不应该允许写的操作，因为这样会改变程序的行为。而在分页系统中，因为一个页不是一个逻辑实体，代码和数据可能混合在一起，无法进行安全上的控制。 动态链接： 动态链接是指在作业运行之前，并不把几个目标程序段链接起来。要运行时，先将主程序所对应的目标程序装入内存并启动运行，当运行过程中又需要调用某段时，才将该段(目标程序)调入内存并进行链接。可见，动态链接也要求以段作为管理的单位。 保持兼容性 每个段的作用 名称 存储内容 栈 局部变量、函数参数、返回地址等 堆 动态分配的内存 BSS段 未初始化或初值为0的全局变量和静态局部变量 数据段 已初始化且初值非0的全局变量和静态局部变量 代码段 可执行代码、字符串字面值、只读变量 在将应用程序加载到内存空间执行时，操作系统负责代码段、数据段和BSS段的加载，并在内存中为这些段分配空间。栈也由操作系统分配和管理；堆由程序员自己管理，即显式地申请和释放空间。BSS段、数据段和代码段是可执行程序编译时的分段，运行时还需要栈和堆。 wait sleep的区别，并说明使用场景,wait sleep都会释放cpu资源吗 这题是java的东西，但知道一下也无妨 这两个方法来自不同的类，sleep来自Thread类，和wait来自Object类。 sleep是Thread的静态类方法，谁调用的谁去睡觉，即使在a线程里调用了b的sleep方法，实际上还是a去睡觉，要让b线程睡觉要在b的代码中调用sleep。 sleep方法没有释放锁，而wait方法释放了锁，使得其他线程可以使用同步控制块或者方法。 sleep不出让系统资源；wait是进入线程等待池等待，出让系统资源，其他线程可以占用CPU。一般wait不会加时间限制，因为如果wait线程的运行资源不够，再出来也没用，要等待其他线程调用notify/notifyAll唤醒等待池中的所有线程，才会进入就绪队列等待OS分配系统资源。sleep(milliseconds)可以用时间指定使它自动唤醒过来，如果时间不到只能调用interrupt()强行打断。 sleep必须捕获异常，而wait，notify和notifyAll不需要捕获异常 wait，notify和notifyAll只能在同步控制方法或者同步控制块里面使用，而sleep可以在任何地方使用 系统调用或者说中断的过程，中断的作用是什么，比如说任务调度？软中断 硬中断 中断是指程序执行过程中，遇到急需处理的事件时，暂时中止CPU上现行程序的运行，转去执行相应的事件处理程序，待处理完成后再返回原程序被中断处或调度其他程序执行的过程。操作系统是“中断驱动”的；换言之，中断是激活操作系统的唯一方式。 中断或异常处理执行的代码不是一个进程，而是内核控制路径，它代表异常或中断发生时正在运行的当前进程在内核态执行一个独立的指令序列。内核控制路径比进程更“轻”，其上下文信息比进程上下文信息少得多。而上下文切换后CPU执行的是另一个用户进程。 根据中断源不同，中断事件处理原则为 处理器硬件故障中断：由处理器、内存储器、总线等硬件故障引起。会通过中断请求向CPU请求处理。处理原则为：保护现场，停止设备，停止CPU，向操作员报告并对故障造成的破坏进行估计和恢复，等待人工干预（复位、设置、替换等） 程序性中断：由处理器执行机器指令引起。不同用户往往有不同处理要求，借助于信号机制，操作系统可将所捕获的中断事件原封不动的转交给应用程序自行处理。比如程序运行过程中产生的异常。 访管中断：处理器请求分配外设、请求I/O等时，执行访管指令请求OS服务引起（系统调用通过访管指令和中断机制实现） I/O中断事件：来源于外围设备报告I/O状态的中断事件 时钟中断：由外围设备发出的信号引起的中断事件 中断源可以分为两部分：本地中断源和外部中断源。本地中断源有些场合又称为软件中断，因为没有具体的硬件与之对应。而那些由具体硬件触发的中断则称为硬件中断。而异常则是程序指令流执行过程中的同步过程，比如程序执行过程中遇到除零错，很显然此时程序无法继续运行，只能处理完了这个异常，才可以继续运行。异常的同步特性和中断的异步又是一个明显的区别。另外在linux中为了让内核延期执行某个任务，也提出了一个软中断（software interrupt）的概念，这点在windows中与之对应的机制为DPC，即延迟过程调用。 内存延迟分配怎么实现的，内存分配的系统调用是什么 Linux内存的延迟分配就是在你未使用内存（均值物理内存）的时候，操作系统是不会真正的分配物理内存的。只有某一页上的内存被访问，则该页才会被实际的映射到物理内存上来，也即开始占用物理内存。 Linux的namespace namespace 是 Linux 内核用来隔离内核资源的方式。通过 namespace 可以让一些进程只能看到与自己相关的一部分资源，而另外一些进程也只能看到与它们自己相关的资源，这两拨进程根本就感觉不到对方的存在。具体的实现方式是把一个或多个进程的相关资源指定在同一个 namespace 中。 Linux namespaces 是对全局系统资源的一种封装隔离，使得处于不同 namespace 的进程拥有独立的全局系统资源，改变一个 namespace 中的系统资源只会影响当前 namespace 里的进程，对其他 namespace 中的进程没有影响。 Linux 内核实现 namespace 的一个主要目的就是实现轻量级虚拟化(容器)服务。在同一个 namespace 下的进程可以感知彼此的变化，而对外界的进程一无所知。这样就可以让容器中的进程产生错觉，认为自己置身于一个独立的系统中，从而达到隔离的目的。也就是说 linux 内核提供的 namespace 技术为 docker 等容器技术的出现和发展提供了基础条件。 用户态和内核态的区别（一般是从特权级考虑的） 对于任何操作系统来说，创建一个进程是核心功能。创建进程要做很多工作，会消耗很多物理资源。比如分配物理内存，父子进程拷贝信息，拷贝设置页目录页表等等，这些工作得由特定的进程去做，所以就有了特权级别的概念。最关键的工作必须交给特权级最高的进程去执行，这样可以做到集中管理，减少有限资源的访问和使用冲突。inter x86架构的cpu一共有四个级别，0-3级，0级特权级最高，3级特权级最低。 当一个进程在执行用户自己的代码时处于用户运行态（用户态），此时特权级最低，为3级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态。Ring3状态不能访问Ring0的地址空间，包括代码和数据；当一个进程因为系统调用陷入内核代码中执行时处于内核运行态（内核态），此时特权级最高，为0级。执行的内核代码会使用当前进程的内核栈，每个进程都有自己的内核栈。 用户运行一个程序，该程序创建的进程开始时运行自己的代码，处于用户态。如果要执行文件操作、网络数据发送等操作必须通过write、send等系统调用，这些系统调用会调用内核的代码。进程会切换到Ring0，然后进入内核地址空间去执行内核代码来完成相应的操作。内核态的进程执行完后又会切换到Ring3，回到用户态。这样，用户态的程序就不能随意操作内核地址空间，具有一定的安全保护作用。这说的保护模式是指通过内存页表操作等机制，保证进程间的地址空间不会互相冲突，一个进程的操作不会修改另一个进程地址空间中的数据。 当在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成一些用户态自己没有特权和能力完成的操作时就会切换到内核态。 用户态切换到内核态的3种方式 系统调用：这是用户态进程主动要求切换到内核态的一种方式。用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。例如fork（）就是执行了一个创建新进程的系统调用。系统调用的机制和新是使用了操作系统为用户特别开放的一个中断来实现，如Linux的int 80h中断。 异常：当cpu在执行运行在用户态下的程序时，发生了一些没有预知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关进程中，也就是切换到了内核态，如缺页异常。 外围设备的中断：当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令而转到与中断信号对应的处理程序去执行，如果前面执行的指令时用户态下的程序，那么转换的过程自然就会是 由用户态到内核态的切换。如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后边的操作等。 这三种方式是系统在运行时由用户态切换到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。从触发方式上看，切换方式都不一样，但从最终实际完成由用户态到内核态的切换操作来看，步骤又是一样的，都相当于执行了一个中断响应的过程。系统调用实际上最终是中断机制实现的，而异常和中断的处理机制基本一致。 端口 用来区分同一主机上的不同服务。端口号是标识主机内唯一的一个进程，IP+端口号就可以标识网络中的唯一进程。在我们通常用的Socket编程中，IP+端口号就是套接字 分类 服务端使用的端口号 预留端口号。取值范围0-1023,这些端口我们编程的时候不能使用，是那些vip应用程序使用的，只有超级用户特权的应用才允许被分配一个预留端口号 登记端口号。取值范围1024-49151，就是我们平时编写服务器使用的端口号范围 客户端 取值范围49152-65535，这部分是客户端进程运行时动态选择的范围，又叫临时端口号 linux服务器性能监测 说一些你常用的linux命令。 写出你熟悉的Linux命令 文件：ls ll -a la 进程和文件：ps,top,df,du,pstree （top命令都能看到哪些信息？） 网络：netstat,ping,curl,traceroute，iptables 文本：cat,vi,wc,grep,awk,sed,head,tail,more,less, 查找：whereis find -n locate which 权限：chmod chown 777 su sudo 定时任务和后台执行：crontab nohup &amp;后台执行 查询进程的相关指令：ps -aux/ps -ef 查询相关端口的指令：netstat -ntl 查询内存使用状态：free -h ，显示的各个字段的含义 Liunx下如何查看共享内存的情况：ipcs -m 基本的操作：复制，删除，重命名，移动 设置开启自启动，设计定时执行 Stat，trace，抓包用什么命令 tcpdump 防火墙的设置 linux中如何查看一个端口是否被占用，被那个进程占用。 http的默认端口是80，怎么将它改为8080端口。 打开$HTTPD_HOME/conf/httpd.conf文件，找到Listen，后面紧跟的是端口号，默认是80，把它修改为你想设置的端口号即可。如果不知道Apache的安装目录，可以用locate httpd.conf命令来查找。 linux中vim怎么统计文件的行数。 如果只是linux下，用wc -l filename :%s/./&amp;/gn 统计字符数 :%s/\\i+/&amp;/gn 统计单词数 :%s/^//n 统计行数 :%s/keyword/&amp;/gn 统计任何地方出现的 “keyword” Linux下查看内存使用命令是什么？查看负载的命令是什么？ Linux下如何查看服务器网络状态？ ifconfig、netstat -an 服务器CPU 100%怎么定位 先用top定位出问题的进程，再用top定位到出问题的线程，再打印线程堆栈查看运行情况 top jstack，日志，gui工具 怎么定位内存泄漏（用jmap把内存dump下来，然后再用工具分析堆栈） Linux大文件怎么查某一行的内容：sed -n ‘x,yp’ filename就可以看第x行到第y行 Linux下TCP服务器都有什么状态？ ESTABLISHED 表示正在通信，TIME_WAIT 表示主动关闭，CLOSE_WAIT 表示被动关闭。 Linux下TIME_WAIT和CLOSE_WAIT区别是什么？ close_wait是被动关闭, time_wait是主动关闭 too many files是怎么产生的，用什么方法可以发现这个问题，怎么解决这个问题 TIME_WAIT和CLOSE_WAIT两种状态如果一直被保持，那么意味着对应数目的通道就一直被占着，而且是“占着茅坑不使劲”，一旦达到句柄数上限，新的请求就无法被处理了，接着就是大量Too Many Open Files异常，tomcat崩溃 发现问题：用命令netstat -n | awk **&#39;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;&#39;** 保持time_wait的解决： 这种情况比较常见，一些爬虫服务器或者WEB服务器（如果网管在安装的时候没有做内核参数优化的话）上经常会遇到这个问题。TIME_WAIT是主动关闭连接的一方保持的状态，对于爬虫服务器来说他本身就是“客户端”，在完成一个爬取任务之后，他就会发起主动关闭连接，从而进入TIME_WAIT的状态，然后在保持这个状态2MSL（max segment lifetime）时间之后，彻底关闭回收资源。为什么要这么做？明明就已经主动关闭连接了为啥还要保持资源一段时间呢？这个是TCP/IP的设计者规定的，主要出于以下两个方面的考虑： 防止上一次连接中的包，迷路后重新出现，影响新连接（经过2MSL，上一次连接中所有的重复包都会消失） 可靠的关闭TCP连接。在主动关闭方发送的最后一个 ack(fin) ，有可能丢失，这时被动方会重新发fin, 如果这时主动方处于 CLOSED 状态 ，就会响应 rst 而不是 ack。所以主动方要处于 TIME_WAIT 状态，而不能是 CLOSED 。另外这么设计TIME_WAIT 会定时的回收资源，并不会占用很大资源的，除非短时间内接受大量请求或者受到攻击。 解决思路很简单，就是让服务器能够快速回收和重用那些TIME_WAIT的资源。修改/etc/sysctl.conf。修改完之后执行/sbin/sysctl -p让参数生效。 保持close_wait的解决： TIME_WAIT状态可以通过优化服务器参数得到解决，因为发生TIME_WAIT的情况是服务器自己可控的，要么就是对方连接的异常，要么就是自己没有迅速回收资源，总之不是由于自己程序错误导致的。 但是CLOSE_WAIT就不一样了，如果一直保持在CLOSE_WAIT状态，那么只有一种情况，就是在对方关闭连接之后服务器程序自己没有进一步发出ack信号。换句话说，就是在对方连接关闭之后，程序里没有检测到，或者程序压根就忘记了这个时候需要关闭连接，于是这个资源就一直被程序占着。 所以问题一定在程序里，检查就完事了 缓冲区溢出攻击原理，buffer 和 cache区别 缓冲区溢出的含义是为缓冲区提供了多于其存储容量的数据，就像往杯子里倒入了过量的水一样。通常情况下，缓冲区溢出的数据只会破坏程序数据，造成意外终止。但是如果有人精心构造溢出数据的内容，那么就有可能获得系统的控制权 缓冲区在系统中的表现形式是多样的，高级语言定义的变量、数组、结构体等在运行时可以说都是保存在缓冲区内的，因此所谓缓冲区可以更抽象地理解为一段可读写的内存区域，缓冲区攻击的最终目的就是希望系统能执行这块可读写内存中已经被蓄意设定好的恶意代码。按照冯·诺依曼存储程序原理，程序代码是作为二进制数据存储在内存的，同样程序的数据也在内存中，因此直接从内存的二进制形式上是无法区分哪些是数据哪些是代码的，这也为缓冲区溢出攻击提供了可能。 由于栈是低地址方向增长的，因此局部数组buffer的指针在缓冲区的下方。当把data的数据拷贝到buffer内时，超过缓冲区区域的高地址部分数据会“淹没”原本的其他栈帧数据，根据淹没数据的内容不同，可能会有产生以下情况： 淹没了其他的局部变量。如果被淹没的局部变量是条件变量，那么可能会改变函数原本的执行流程。这种方式可以用于破解简单的软件验证。 淹没了ebp的值。修改了函数执行结束后要恢复的栈指针，将会导致栈帧失去平衡。 淹没了返回地址。这是栈溢出原理的核心所在，通过淹没的方式修改函数的返回地址，使程序代码执行“意外”的流程！ 淹没参数变量。修改函数的参数变量也可能改变当前函数的执行结果和流程。 淹没上级函数的栈帧，情况与上述4点类似，只不过影响的是上级函数的执行。当然这里的前提是保证函数能正常返回，即函数地址不能被随意修改（这可能很麻烦！）。 IO多路复用技术： IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程。本质是通过一种机制（系统内核缓冲I/O数据），让单个进程可以监视多个文件描述符，一旦某个描述符就绪（一般是读就绪或写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的 IO多路复用适用如下场合： 当客户处理多个描述字时（一般是交互式输入和网络套接口），必须使用I/O复用。 当一个客户同时处理多个套接口时，而这种情况是可能的，但很少出现。 如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I/O复用。 如果一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用。 如果一个服务器要处理多个服务或多个协议，一般要使用I/O复用。 与多进程和多线程技术相比，I/O多路复用技术的最大优势是系统开销小，系统不必创建进程/线程，也不必维护这些进程/线程，从而大大减小了系统的开销。 select函数 说的通俗一点就是各个客户端连接的文件描述符也就是套接字，都被放到了一个集合中，调用select函数之后会一直监视这些文件描述符中有哪些可读，如果有可读的描述符那么我们的工作进程就去读取资源。 该函数准许进程指示内核等待多个事件中的任何一个发送，并只在有一个或多个事件发生或经历一段指定的时间后才唤醒。函数原型如下 12345#include &lt;sys/select.h&gt;#include &lt;sys/time.h&gt;int select(int maxfdp1,fd_set *readset,fd_set *writeset,fd_set *exceptset,const struct timeval *timeout)返回值：就绪描述符的数目，超时返回0，出错返回-1 函数参数介绍如下 第一个参数maxfdp1指定待测试的文件描述字(file description)个数，它的值是待测试的最大描述字加1（因此把该参数命名为maxfdp1），描述字0、1、2…maxfdp1-1均将被测试。因为文件描述符是从0开始的。 中间的三个参数readset、writeset和exceptset指定我们要让内核测试读、写和异常条件的描述字。如果对某一个的条件不感兴趣，就可以把它设为空指针。struct fd_set可以理解为一个集合，这个集合中存放的是文件描述符 timeout告知内核等待所指定描述字中的任何一个就绪可花多少时间。其timeval结构用于指定这段时间的秒数和微秒数。 select 在一个进程内可以维持最多 1024 个连接 select过程如下 使用copy_from_user从用户空间拷贝fd_set到内核空间 注册回调函数__pollwait 遍历所有fd，调用其对应的poll方法（对于socket，这个poll方法是sock_poll，sock_poll根据情况会调用到tcp_poll,udp_poll或者datagram_poll） 以tcp_poll为例，其核心实现就是__pollwait，也就是上面注册的回调函数。 __pollwait的主要工作就是把current（当前进程）挂到设备的等待队列中，不同的设备有不同的等待队列，对于tcp_poll来说，其等待队列是sk-&gt;sk_sleep（注意把进程挂到等待队列中并不代表进程已经睡眠了）。在设备收到一条消息（网络设备）或填写完文件数据（磁盘设备）后，会唤醒设备等待队列上睡眠的进程，这时current便被唤醒了。 poll方法返回时会返回一个描述读写操作是否就绪的mask掩码，根据这个mask掩码给fd_set赋值。 如果遍历完所有的fd，还没有返回一个可读写的mask掩码，则会调用schedule_timeout是调用select的进程（也就是current）进入睡眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的进程。如果超过一定的超时时间（schedule_timeout指定），还是没人唤醒，则调用select的进程会重新被唤醒获得CPU，进而重新遍历fd，判断有没有就绪的fd。 把fd_set从内核空间拷贝到用户空间。 select缺点 每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大 每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大 select支持的文件描述符数量太小了，默认是1024 poll函数 poll的机制与select类似，与select在本质上没有多大差别，管理多个描述符也是进行轮询，根据描述符的状态进行处理，但是poll没有最大文件描述符数量的限制。poll和select同样存在一个缺点就是，包含大量文件描述符的数组被整体复制于用户态和内核态的地址空间之间，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大。 poll函数原型如下 12# include &lt;poll.h&gt;int poll ( struct pollfd * fds, unsigned int nfds, int timeout); pollfd结构体定义如下 12345struct pollfd &#123; int fd; /* 文件描述符 */ short events; /* 等待的事件 */ short revents; /* 实际发生了的事件 */&#125; ; 每一个pollfd结构体指定了一个被监视的文件描述符，可以传递多个结构体，指示poll()监视多个文件描述符。每个结构体的events域是监视该文件描述符的事件掩码，由用户来设置这个域。revents域是文件描述符的操作结果事件掩码，内核在调用返回时设置这个域。events域中请求的任何事件都可能在revents域中返回。 使用poll()和select()不一样，你不需要显式地请求异常情况报告。 成功时，poll()返回结构体中revents域不为0的文件描述符个数；如果在超时前没有任何事件发生，poll()返回0；失败时，poll()返回-1 其实select跟poll是差不多的，复用了很多代码，只是记录监听events的数据结构不一样 epoll函数 epoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。 epoll操作过程需要三个接口，分别如下 1234#include &lt;sys/epoll.h&gt;int epoll_create(int size);int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); int epoll_create(int size) 创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大。这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值。需要注意的是，当创建好epoll句柄后，它就是会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event) epoll的事件注册函数，它不同于select()是在监听事件时告诉内核要监听什么类型的事件，而是在这里先注册要监听的事件类型。 int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout) 等待事件的产生，类似于select()调用。参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。 epoll对文件描述符的操作有两种模式：LT（level trigger，水平触发）和ET（edge trigger，边缘触发）。LT模式是默认模式，LT模式与ET模式的区别如下： LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。 ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。 ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 epoll把epoll实例创建、events增删改还有events轮询都分开了，这样的话epoll实例就可以被同一个进程中的所有线程共享。epoll跟poll一样，使用链表节点记录监听events，但是呢它有三个链表型结构（就绪链表、辅助链表、红黑树），首先想要监听的events的节点被放到红黑树里，这样可以加快events节点的访问。events就绪之后会被挂载到就绪链表里去，当epoll_wait从内核空间向用户空间写出就绪events的时候，会遍历就绪链表，同时这个时候可能还会发生新的就绪events，这个时候已就绪的events不再添加到就绪链表里去，而是使用辅助链表 在epoll_wait调用中，epoll会遍历就绪队列里的每一个events节点，然后通过文件的poll方法再次获取事件的最新状态revents，然后把该events节点从就绪链表中删除。当revents中包含我们关心的事件events的话，LT模式还会把该节点重新加入到就绪队列里，而ET模式也就是edge边界模式不会。 这么做有什么影响呢，假设我们监听一个管道可读，当事件就绪之后，我们只读了部分内容，还有部分内容没有读。当我们再次epoll_wait的时候，对LT模式来说，就绪队列里还有这个事件的节点，再次获取状态，然后返回这个这个事件；对ET模式来说，就绪队列里没有这个事件的节点了，所以也就不会再对它进行通知了。那LT模式中的这个事件节点什么时候被删除呢，假设第一次epoll_wait的时候，我们把管道里的内容全部读完了，下次epoll_wait遍历到这个节点然后重新获取它的状态的时候，它已经不再就绪了，因为管道空了，这个时候LT模式就不会再把这个节点重新添加到就绪队列里了。 LT模式和ET模式各自的应用场所：LT模式比较慢，但是比较安全，也就是如果真的是就绪的话它会再次通知你；而ET模式比较快，但是有可能造成事件的丢失，这就可能让程序永远阻塞。LT为了担责，降低了效率，而ET为了效率将责任推给了用户 与select的三个缺点相比： 对于第一个缺点，epoll的解决方案在epoll_ctl函数中。每次注册新的事件到epoll句柄中时（在epoll_ctl中指定EPOLL_CTL_ADD），会把所有的fd拷贝进内核，而不是在epoll_wait的时候重复拷贝。epoll保证了每个fd在整个过程中只会拷贝一次。 对于第二个缺点，epoll的解决方案不像select或poll一样每次都把current轮流加入fd对应的设备等待队列中，而只在epoll_ctl时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表。epoll_wait的工作实际上就是在这个就绪链表中查看有没有就绪的fd，利用schedule_timeout()实现睡一会，判断一会的效果，和select实现中的第7步是类似的 对于第三个缺点，epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。 总结 select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd内存碎片（外碎片和内碎片）集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。 select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。 惊群效应 对于操作系统来说，多个进程/线程在等待同一资源是，也会产生类似的效果，其结果就是每当资源可用，所有的进程/线程都来竞争资源，造成的后果： 系统对用户进程/线程频繁的做无效的调度、上下文切换，系统系能大打折扣。 为了确保只有一个线程得到资源，用户必须对资源操作进行加锁保护，进一步加大了系统开销。 对于惊群效应的场景描述，最常见的就是对于socket操作符的accept操作的描述。当多个用户进程/线程同时监听同一个端口时，由于实际上一个请求过来，只有一个进程/线程accept成功，所以就会产生惊群效应。 linux操作系统在内核层面很早就解决了这个问题，一个请求过来，内核只会唤醒一个进程来accept，这样就没有惊群现象了。但是在很多场景下，只要有竞争，就可能会出现惊群效应。比如常见的生产者-消费者模型，一般来说消费可能会比较耗时，所以消费者会有多个。当突然有生产者往队列里面投了一个job时，这些消费者就会一哄而上去队列中抢这个job，这就发生了惊群效应。 创建一个TCP服务器的步骤是什么 从汇编去解释一下引用（我们先来看看左值引用吧（画图示意），左值引用封装了一个指针，指针指向被引用的对象，每次使用这个引用就是解引用这个被封装的指针。右值引用的话，底层是将原来的对象进行了一份内存拷贝，然后封装了对这个拷贝的指针。因为是拷贝，所以实际上右值引用其实也是左值，emmm…STL里面有一个forkward函数，它的作用就是用来进行右值引用的类型恢复…） 惊群效应了解吗，如何解决惊群呢（我先举个例子吧，linux内核中的等待队列，等待队列中的等待节点有两种状态，一种是互斥等待，一种是非互斥等待。如果某个事件一发生，会唤醒对应的等待队列中的所有非互斥等待节点，而如果是互斥等待节点的话，可以选择唤醒所有节点，也可以选择唤醒指定个节点。Pthread线程库里面也有一个很好的例子，pthread_cond_signal与pthread_cond_broadcast，signal只通知一个信号量，而broadcast会通知所有信号量。但是有时候就绪的事件只能满足一个用户，如果选择广播的话就会通知所有用户，然后最终只有一个用户可以得到满足，其他用户还是被阻塞导致不必要的性能浪费） 闪存介质的写放大问题，如何优化？ 计算机的磁盘读取文件的过程","categories":[],"tags":[]},{"title":"","slug":"c++","date":"2021-03-25T10:20:55.615Z","updated":"2021-03-25T10:20:55.615Z","comments":true,"path":"2021/03/25/c++/","link":"","permalink":"http://example.com/2021/03/25/c++/","excerpt":"","text":"腾讯后端开发 C++ 32位机和64位机中数据类型的区别 linux下，long和指针所占字节不一致，都从4byte变成8byte windows下，指针所占字节不一致，从4byte变成8byte 代码在内存中的分布都有哪些区？宏定义存在刚才你说的哪个区域？堆栈有什么区别啊？堆中的数据会回收吗？ 5个区，堆、栈、自由存储区、全局/静态存储区、常量存储区 栈，就是那些由编译器在需要的时候分配，在不需要的时候自动清除的变量的存储区。里面的变量通常是局部变量、函数参数、函数返回信息等。 对于栈来讲，它的生长方向是向下的，是向着内存地址减小的方向增长。栈有2种分配方式：静态分配和动态分配。静态分配是编译器完成的，比如局部变量的分配。动态分配由alloca函数进行分配，但是栈的动态分配和堆是不同的，他的动态分配是由编译器进行释放，无需我们手工实现。栈是机器系统提供的数据结构，计算机会在底层对栈提供支持，分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了栈的效率比较高。 堆，就是那些由new分配的内存块，他们的释放编译器不去管，由我们的应用程序去控制。堆内存用来保存类和对象。一般一个new就要对应一个delete。如果没有被释放掉，那么在程序结束后，操作系统会自动回收。 对于堆来讲，生长方向是向上的，也就是向着内存地址增加的方向。堆都是动态分配的，没有静态分配的堆。堆是C/C++函数库提供的，它的机制是很复杂的，例如为了分配一块内存，库函数会按照一定的算法在堆内存中搜索可用的足够大小的空间，如果没有足够大小的空间，就有可能调用系统功能去增加程序数据段的内存空间，这样就有机会分到足够大小的内存，然后进行返回。显然，堆的效率比栈要低得多。 全局/静态存储区，全局变量和静态变量被分配到同一块内存中 常量存储区，这是一块比较特殊的存储区，他们里面存放的是常量，不允许修改（当然，你要通过非正当手段也可以修改，而且方法很多） 宏定义没有分配在哪个区，因为宏只是在编译前的预处理做文本替换 堆中的数据在程序运行过程中不会自动回收，全靠程序逻辑回收，程序结束后被操作系统回收。 引用 引用是C++语法做的优化，引用的本质还是靠指针来实现的。引用相当于变量的别名。 引用可以改变指针的指向，还可以改变指针所指向的值。 声明引用的时候必须初始化，且一旦绑定，不可把引用绑定到其他对象；即引用必须初始化，不能对引用重定义；对引用的一切操作，就相当于对原对象的操作。 顶层const，底层const 这个是常识了 const int* p=&amp;a; //底层 int* const p=&amp;a; //顶层 volatile volatile 关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素更改，比如：操作系统、硬件或者其它线程等。遇到这个关键字声明的变量，编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问。声明时语法：int volatile vInt; 当要求使用 volatile 声明的变量的值的时候，系统总是重新从它所在的内存读取数据，即使它前面的指令刚刚从该处读取过数据。而且读取的数据立刻被保存。 volatile 指出 i 是随时可能发生变化的，每次使用它的时候必须从 i 的地址中读取，因而编译器生成的汇编代码会重新从i的地址读取数据放在 b 中。而优化做法是，由于编译器发现两次从 i读数据的代码之间的代码没有对 i 进行过操作，它会自动把上次读的数据放在 b 中。而不是重新从 i 里面读。这样以来，如果 i 是一个寄存器变量或者表示一个端口数据就容易出错，所以说 volatile 可以保证对特殊地址的稳定访问。 一般说来，volatile用在如下的几个地方： 中断服务程序中修改的供其它程序检测的变量需要加volatile 多任务环境下各任务间共享的标志应该加volatile 存储器映射的硬件寄存器通常也要加volatile说明，因为每次对它的读写都可能由不同意义 volatile跟const一样，也有顶层底层之分 可以把一个非volatile int赋给volatile int，但是不能把非volatile对象赋给一个volatile对象。 左值、右值 左值代表一个在内存中占有确定地址的对象，右值可以在内存也可以在CPU寄存器。一个对象被用作右值时，使用的是它的内容(值)，被当作左值时，使用的是它的地址。 函数并不是只能返回右值，也可以返回左值。C++从函数中返回左值的能力对于实现一些运算符重载时很重要。 不是所有的左值都可修改，比如有const限定的就不行 通常来说，语言构造一个对象的值要求右值作为参数 解引用可以把右值转化为左值，而取地址符&amp;拿左值作为参数得到一个右值 左值引用、右值引用 左值引用的语法是type &amp;Name = lvalueExpression 右值引用的语法是type &amp;&amp;Name = rvalueExpression 右值引用的意义在于延长右值的生存期。因为右值在表达式结束后就会消亡。如果想继续使用右值，那就会动用昂贵的拷贝构造函数。 右值引用是用来支持转移语义的。转移语义可以将资源 ( 堆，系统对象等 ) 从一个对象转移到另一个对象，这样能够减少不必要的临时对象的创建、拷贝以及销毁，能够大幅度提高 C++ 应用程序的性能。临时对象的维护 ( 创建和销毁 ) 对性能有严重影响。 右值引用是对临时对象的一种引用，它是在初始化时完成引用的，但是右值引用不代表引用临时对象后，就不能改变右值引用所引用对象的值。仍然可以在初始化后改变临时对象的值。 如果一个右值引用有名字，那么它是左值，否则为右值 malloc/free和new/delete有什么区别？(malloc: 咩力克) malloc/free是C语言提供的系统函数，需要头文件支持；new/delete是C++关键字(运算符)，需要编译器支持。 使用new操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算。而malloc则需要显式地指出所需内存的尺寸。 new操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，无须进行类型转换，故new是符合类型安全性的操作符。而malloc内存分配成功则是返回void* ，需要通过强制类型转换将void*指针转换成我们需要的类型。 new会先调用operator new函数，申请足够的内存（通常底层使用malloc实现），然后调用类型的构造函数，初始化成员变量，最后返回自定义类型指针。delete先调用析构函数，然后调用operator delete函数释放内存（通常底层使用free实现）。malloc/free是库函数，只能动态的申请和释放内存，无法强制要求其做自定义类型对象构造和析构工作，所以得到的一片新内存中，其值将是随机的。 new操作符从自由存储区（free store）上为对象动态分配内存空间，而malloc函数从堆上动态分配内存，操作系统中有一个记录空闲内存地址的链表，当操作系统收到程序的申请时，就会遍历该链表，然后就寻找第一个空间大于所申请空间的堆结点，然后就将该结点从空闲结点链表中删除，并将该结点的空间分配给程序。自由存储区是C++基于new操作符的一个抽象概念，凡是通过new操作符进行内存申请，该内存即为自由存储区。而堆是操作系统中的术语，是操作系统所维护的一块特殊内存，用于程序的内存动态分配，C语言使用malloc从堆上分配内存，使用free释放已分配的对应内存。自由存储区不等于堆，如上所述，布局new就可以不位于堆中。 C++允许重载new/delete操作符，malloc不允许重载。 new内存分配失败时，会抛出bad_alloc异常。malloc分配内存失败时返回NULL。 如果用free释放“new创建的动态对象”，那么该对象因无法执行析构函数而可能导致程序出错。如果用delete释放“malloc申请的动态内存”，结果也会导致程序出错。 空指针可以释放无数次，相当于什么都没有做 delete指针之后应重设指针的值为nullptr，否则指针会指向之前的地址，变成悬垂指针。 内存泄漏对于new和malloc都能检测出来，而new可以指明是哪个文件的哪一行，malloc不可以。 重写(override)和重载(overload)的区别 override是指派生类重写基类的虚函数，重写的函数必须有一致的参数表和返回值。 overload约定成俗的被翻译为“重载”。是指编写一个与已有函数同名但是参数表不同的函数。 相同参数不同返回值可以重载吗？不能 函数隐藏、函数覆盖 函数隐藏是指派生类中函数与基类中的函数同名，但是这个函数在基类中并没有被定义为虚函数，这种情况就是函数的隐藏。所谓隐藏是指使用常规的调用方法，派生类对象访问这个函数时，会优先访问派生类中的这个函数，基类中的这个函数对派生类对象来说是隐藏起来的。 但是隐藏并不意味这不存在或完全不可访问。 函数覆盖特指由基类中定义的虚函数引发的一种多态现象。在某基类中声明为 virtual 并在一个或多个派生类中被重新定义的成员函数，用法格式为：virtual 函数返回类型 函数名（参数表） {函数体}；实现多态性，通过指向派生类的基类指针或引用，访问派生类中同名覆盖成员函数。函数覆盖条件有三： 基类中的成员函数被virtual关键字声明为虚函数 生类中该函数必须和基类中函数的名称、参数类型和个数等完全一致 将派生类的对象赋给基类指针或者引用，实现多态 函数覆盖（多态）实现了一种基类访问（不同）派生类的方法。我们把它称为基类的逆袭。 类和结构体的区别（博主一般以类是引用类型，结构体是值类型入手） 最本质的区别是继承访问权限。到底默认是public继承还是private继承，取决于子类而不是基类。 struct作为数据结构的实现体，它默认的数据访问控制是public的，而class作为对象的实现体，它默认的成员变量访问控制是private的 class这个关键字还用于定义模板参数，就像typename。但关键字struct不用于定义模板参数 怎么禁止隐式转换 使用explicit关键字，在类的构造函数前面加上该关键字就能禁止隐式转换。 字节对齐，怎么让编译器按指定大小对齐的？ 许多实际的计算机系统对基本类型数据在内存中存放的位置有限制，它们会要求这些数据的首地址的值是某个数k(通常它为4的倍数，这就是所谓的字节对齐，而这个k则被称为该数据类型的对齐模数(alignment modulus)。当一种类型S的对齐模数与另一种类型T的对齐模数的比值是大于1的整数，我们就称类型S的对齐要求比T强(严格)，而称T比S弱(宽松)。 内置类型的自身对齐模数(有符号无符号相同) char 1 short 2 int 4 float 4 double 8 自定义类型的自身对齐模数等同于其成员中最大的自身对齐模数 通过预编译命令#pragma pack(n)来指定对齐模数，n为2的整数幂 有效对齐模数：指定对齐模数与类型自身对齐模数的较小的值，就是实际生效的对齐模数。 字节对齐的细节和具体编译器实现相关，但一般而言，满足三个准则： 结构体变量的首地址能够被其最宽基本类型成员的大小所整除 结构体每个成员相对于结构体首地址的偏移量都是成员大小的整数倍，如有需要编译器会在成员之间加上填充字节 结构体的总大小为结构体最宽基本类型成员大小的整数倍，如有需要编译器会在最末一个成员之后加上填充字节 在C++类里在没有任何数据类型变量的时候，会有一个字节的空间占用，如果有数据类型变量就会有字节对齐 C++当中一个class,拥有一个char和int,加起来占用多大内存空间？ 我的电脑跑出来是8byte，因为字节对齐，所以4+4==8 首先，类大小的计算遵循结构体的对齐原则 类的大小与普通数据成员有关，与成员函数和静态成员无关。即普通成员函数，静态成员函数，静态数据成员，静态常量数据成员均对类的大小无影响 虚函数对类的大小有影响，是因为虚函数表指针带来的影响。有虚函数表会有一个指向虚函数表的指针，这个指针受字节对齐影响。不管有没有发生虚函数的覆盖或者增加，大小计算方法不变。继承了多少个类，就会有多少个虚函数表，就会有多少个指针。 虚继承对类的大小有影响，是因为虚基表指针带来的影响。不管是否虚继承，gcc都是将虚表指针在整个继承关系中共享的，不共享的是指向虚基类的指针。更多看这里。 空类的大小是一个特殊情况，空类的大小为1。C++标准规定，凡是一个独立的(非附属)对象都必须具有非零大小，不同的对象不能具有相同的地址。 静态数据成员之所以不计算在类的对象大小内，是因为类的静态数据成员被该类所有的对象所共享，并不属于具体哪个对象，静态数据成员定义在内存的全局区 有两种特殊情况需要注意： 第一种情况，涉及到空类的继承。当派生类继承空类后，派生类如果有自己的数据成员，而空基类的一个字节并不会加到派生类中去。 第二种情况，一个类包含一个空类对象数据成员。这种情况下空类的1字节会被算进去，而且受到字节对齐的影响。 vector vector底层实现为数组。有三个指针：_Myfirst, _Mylast, _Myend。first和end指向数组的一头一尾，last指向现在用到的位置。size=last-first, capacity=end-first，分别对应于resize()和reserve()这两个函数 vector是一个封装了动态大小数组的顺序容器，按照严格的线性顺序排序。可以通过元素在序列中的位置访问对应的元素。 vector提供了在序列末尾相对快速地添加/删除元素的操作。 push_back是O(c)的，这是因为vector扩容是按照倍数扩大来保证的。如果扩容是固定大小扩容，push_back就会变成O(n)的。如果以成倍方式增长，假定插入n个元素，倍增因子为m。那么要完成这n个元素的push_back，需要重新分配$\\log_mn$次内存，第i次重新分配会复制$m^i$个旧空间的元素，总时间复杂度约为$\\frac{nm}{m-1}$。均摊为常量。如果以大于等于2倍的方式扩容，下一次申请的内存会大于之前分配内存的总和，导致之前分配的内存不能再被使用。所以其实大于1小于2是最合适的。 vector预留空间不足时，push_back之前会先调整vector内存大小，效率会变得很低。 vector使用一个内存分配器对象来动态地处理它的存储需求。vector的内存管理策略是：一旦空间不足，则增长一倍。重新分配内存时会拷贝当前已有的所有元素到新的内存区域。如果已有元素很多，这个操作将变得非常昂贵。如何避免重新分配内存？使用reserve。该函数会分配一块指定大小的空间，但不进行任何初始化，所以分配出来的空间不包含元素，也就不能访问。然后用同样的方式使用push_back函数，此时只要不超过之前reserve的空间，vector不会进行内存重新分配，只是简单的依次往后摆放。 创建一个 vector ，里面存了5个元素 1 2 3 4 5，把迭代器指向 5，然后在 vector 的最前面插入一个 0 ，问刚才那个迭代器指向几？写了，答案是4。插入前后迭代器地址不变。 vector的容量增长的题目，vector a; push_back八次对象，求总共调用多少次拷贝构造函数。答案是4次。 list list底层是一个双向链表(某些版本的STL里是双向循环链表)，支持快速增删。相比双向链表结构的好处是在构建 list 容器时，只需借助一个指针即可轻松表示 list 容器的首尾元素。 list节点包含指向上一个节点的prev指针，指向下一个节点的next指针，存储值的成员变量myval list每分配一个元素都会从内存中分配,每删除一个元素都会释放它占用的内存. 迭代器的移动就是通过操作节点的指针实现的。 为了更方便地实现 list 模板类提供的函数，该模板类在构建容器时，会刻意在容器链表中添加一个空白节点，并作为 list 链表的首个节点（又称头节点）。使用双向链表实现的 list 容器，其内部通常包含 2 个指针，并分别指向链表中头部的空白节点和尾部的空白节点（也就是说，其包含 2 个空白节点） list&lt;指针&gt;完全是性能最低的做法，这种情况下还是使用vector&lt;指针&gt;好，因为指针没有构造与析构，也不占用很大内存 set set是有序集合，内部数据结构为红黑树 插入和查找效率都是$\\log{N}$的，仅仅需要指针操作节点即可完成，不涉及到内存移动和拷贝，map也一样。插入的时候只需要稍做变换，把节点的指针指向新的节点就可以了。删除的时候类似，稍做变换后把指向删除节点的指针指向其他节点也OK了。这里的一切操作就是指针换来换去，和内存移动没有关系。 每次insert之后，以前保留的迭代器不会失效。删了才会失效，而且删了的那部分，迭代器指向的内存和值都没变。 存储自定义类型时需要重载&lt; map 内部数据结构也是红黑树，查询很快，插入较慢(因为要维护红黑树) 存储自定义类型时需要重载&lt; unordered_map (C++11) unordered_map记录元素的hash值，根据hash值判断元素是否相同。即unordered_map内部元素是无序的，而map中的元素是按照二叉搜索树存储（用红黑树实现），进行中序遍历会得到有序遍历。所以使用时map的key需要定义operator&lt;。而unordered_map需要定义hash_value函数并且重载operator==。 deque 双端队列。底层数据结构为一个中央控制器和多个缓冲区，支持首尾（中间不能）快速增删，也支持随机访问。 deque也是在堆中保存内容的.它的保存形式如下: [堆1] –&gt; [堆2] –&gt;[堆3] –&gt; … 每个堆保存好几个元素,然后堆和堆之间有指针指向。 stack和queue 他们都是对容器的再封装，所以应该叫适配器。底层一般用list或deque实现，然后封闭头部即可。 priority_queue 优先队列，底层用堆来实现，队首元素一定是优先级最高的一个 STL容器的数据实际存在什么位置？ 比如vector，指针会存在栈里，元素会存在堆里。 STL迭代器什么情况下会失效，各个容器都说一下 vector在push_back和pop_back时都会引起迭代器失效。erase迭代器失效是在删除一个元素的时候，后面的元素要向前挪动，所以迭代器指向的位置就会被前面的覆盖，这时候++迭代器，就会跳过删除元素的后一个。正确用法是不要在循环里it++，erase方法会返回被删除的元素的下一个元素的迭代器。 list迭代器失效也发生在erase中。当迭代器指向的节点被删除后，迭代器++会失效 增加元素时，对于vector和string，如果容器内存被重新分配，iterators,pointers,references失效；如果没有重新分配，那么插入点之前的iterator有效，插入点之后的iterator失效；对于deque，如果插入点位于除front和back的其它位置，iterators,pointers,references失效；当我们插入元素到front和back时，deque的迭代器失效，但reference和pointers有效；对于list和forward_list，所有的iterator,pointer和refercnce有效。 删除元素时，对于vector和string，插入点之前的iterators,pointers,references有效；off-the-end迭代器总是失效的；对于deque，如果插入点位于除front和back的其它位置，iterators,pointers,references失效；当我们插入元素到front和back时，off-the-end失效，其他的iterators,pointers,references有效；对于list和forward_list，所有的iterator,pointer和refercnce有效。 在循环中refresh迭代器，当处理vector,string,deque时，当在一个循环中可能增加或移除元素时，要考虑到迭代器可能会失效的问题。一定要refresh迭代器。 在循环不变式中不要store off-the-end迭代器。增加或移除元素之后，off-the-end失效了，不store的话，每次从end()函数中取的都是最新的off-the-end，自然不会失效。 Algorithm里面有哪些内容 挑一些常用的说 不修改序列的：all_of, for_each 修改序列的：fill, swap, reverse, unique 排序：sort 二分查找：upper_bound, lower_bound, binary_search 堆操作：is_heap, make_heap, push/pop/sort_heap min/max next/prev_permutation 深拷贝浅拷贝 简单来说，浅拷贝是增加了一个指针，指向原来已经有的内存；深拷贝是增加一个指针，开辟一块新的内存，让指针指向这块新内存。 在多个指针指向同一块内存时，若该内存被释放之后再次被释放，就会出错。 这个问题写个重载赋值就懂了 Main函数执行之前还会执行什么？ main函数执行之前，主要就是初始化系统相关资源 操作系统创建进程后，把控制权交给程序的入口函数，这个函数往往是运行时库的某个入口函数。 入口函数对运行库和程序运行环境进行初始化，包括堆，I/O，线程，全局变量构造（constructor）等。 调用MAIN函数，正式开始执行程序主体。 执行MAIN完毕，返回入口函数，进行清理工作，包括全局变量析构，堆销毁，关闭I/O等，然后进行系统调用介绍进程 C++ 友元函数、友元类 一个类中可以有 public、protected、private 三种属性的成员，通过对象可以访问 public 成员，只有本类中的函数可以访问本类的 private 成员。现在，我们来介绍一种例外情况——友元（friend）。借助友元（friend），可以使得其他类中的成员函数以及全局范围内的函数访问当前类的 private 成员。 在当前类以外定义的、不属于当前类的函数也可以在类中声明，但要在前面加 friend 关键字，这样就构成了友元函数。友元函数可以是不属于任何类的非成员函数，也可以是其他类的成员函数。 注意，友元函数不同于类的成员函数，在友元函数中不能直接访问类的成员，必须要借助对象。必须通过参数传递对象（可以直接传递对象，也可以传递对象指针或对象引用），并在访问成员时指明对象。 friend 函数不仅可以是全局函数（非成员函数），还可以是另外一个类的成员函数。一个函数可以被多个类声明为友元函数，这样就可以访问多个类中的 private 成员。 不仅可以将一个函数声明为一个类的“朋友”，还可以将整个类声明为另一个类的“朋友”，这就是友元类。友元类中的所有成员函数都是另外一个类的友元函数。 友元的关系是单向的而不是双向的。如果声明了类 B 是类 A 的友元类，不等于类 A 是类 B 的友元类，类 A 中的成员函数不能访问类 B 中的 private 成员。 友元的关系不能传递。如果类 B 是类 A 的友元类，类 C 是类 B 的友元类，不等于类 C 是类 A 的友元类。 C++继承 搞清楚公有继承、保护继承、私有继承就行这里 虚继承 为了解决从不同途径继承来的同名的数据成员在内存中有不同的拷贝造成数据不一致问题，将共同基类设置为虚基类。这时从不同的路径继承过来的同名数据成员在内存中就只有一个拷贝，同一个函数名也只有一个映射。这样不仅就解决了二义性问题，也节省了内存，避免了数据不一致的问题。 虚继承的目的是让某个类做出声明，承诺愿意共享它的基类。其中，这个被共享的基类就称为虚基类。在这种机制下，不论虚基类在继承体系中出现了多少次，在派生类中都只包含一份虚基类的成员。 实例化顺序是，首先执行虚基类的构造函数，多个虚基类的构造函数按照被继承的顺序构造；执行基类的构造函数，多个基类的构造函数按照被继承的顺序构造；执行成员对象的构造函数，多个成员对象的构造函数按照申明的顺序构造；执行派生类自己的构造函数。析构以与构造相反的顺序执行。 在多继承情况下，虚基类关键字的作用范围和继承方式关键字相同，只对紧跟其后的基类起作用。 声明了虚基类之后，虚基类在进一步派生过程中始终和派生类一起，维护同一个基类子对象的拷贝。 观察类构造函数的构造顺序，拷贝也只有一份。 必须在虚派生的真实需求出现前就已经完成虚派生的操作。虚派生只影响从指定了虚基类的派生类中进一步派生出来的类，它不会影响派生类本身。 虚函数原理，虚函数与纯虚函数 虚函数是C++中用于实现多态(polymorphism)(同一代码可以产生不同效果的特点，被称为多态)的机制，核心理念就是通过基类访问派生类定义的函数。 虚函数虚在所谓“推迟联编”或者“动态联编”上，一个类函数的调用并不是在编译时刻被确定的，而是在运行时刻被确定的。由于编写代码的时候并不能确定被调用的是基类的函数还是哪个派生类的函数，所以被成为“虚”函数。 虚函数只能借助于指针或者引用来达到多态的效果 虚函数实际上是如何被编译器处理的呢？编译器发现一个类中有被声明为virtual的函数，就会为其创建一个虚函数表，也就是VTABLE。VTABLE实际上是一个函数指针的数组，每个虚函数占用这个数组的一个slot。一个类只有一个VTABLE，不管它有多少个实例。派生类有自己的VTABLE，但是派生类的VTABLE与基类的VTABLE有相同的函数排列顺序，同名的虚函数被放在两个数组的相同位置上。在创建类实例的时候，编译器还会在每个实例的内存布局中增加一个vptr字段，该字段指向本类的VTABLE。通过这些手段，编译器在看到一个虚函数调用的时候，就会将这个调用改写。 基类声明的虚函数，在派生类中也是虚函数，即使不再使用virtual关键字。 在基类中仅仅给出声明，不对虚函数实现定义，而是在派生类中实现。这个虚函数称为纯虚函数。普通函数如果仅仅给出它的声明而没有实现它的函数体，这是编译不过的。纯虚函数没有函数体。纯虚函数的意思是：我是一个抽象类！不要把我实例化！纯虚函数用来规范派生类的行为，实际上就是所谓的“接口”。它告诉使用者，我的派生类都会有这个函数。 private虚函数的语意是：最好重写这个函数，但是不要管它如何使用，也不要调用这个函数。 一个类的虚函数在它自己的构造函数和析构函数中被调用的时候，它们就变成普通函数了。也就是说不能在构造函数和析构函数中让自己“多态”。 在你设计一个基类的时候，如果发现一个函数需要在派生类里有不同的表现，那么它就应该是虚的。从设计的角度讲，出现在基类中的虚函数是接口，出现在派生类中的虚函数是接口的具体实现。通过这样的方法，就可以将对象的行为抽象化。 其实虚函数表的本质就是一种迟后联编的过程，正常编译都是先期联编的，但是当代码遇到了virtual时，就会把它当做迟后联编，但是为了迟后编译，我么就生成了局部变量–虚函数表，这就增大了一些空间上的消耗。（前提是两个函数的返回类型，参数类型，参数个数都得相同，不然就起不到多态的作用） 有一种特殊的情况，那就是如果基类中虚函数返回一个基类指针或引用，派生类中返回一个派生类的指针或引用，则c++将其视为同名虚函数而进行迟后联编 使用虚函数的一些限制： 只有类成员函数才能声明为虚函数，这是因为虚函数只适用于有继承关系的类对象中。 静态成员函数不能说明为虚函数，因为静态成员函数不受限与某个对象，整个内存中只有一个，所以不会出现混淆的情况 内联函数不可以被继承，因为内联函数是不能子啊运行中动态的确认其位置的。 构造函数不可以被继承。 析构函数可以被继承，而且通常声明为虚函数。 抽象类 含有纯虚函数的类被称为抽象类。抽象类只能作为派生类的基类，不能定义对象，但可以定义指针。在派生类实现该纯虚函数后，定义抽象类对象的指针，并指向或引用子类对象。 在定义纯虚函数时，不能定义虚函数的实现部分； 在没有重新定义这种纯虚函数之前，是不能调用这种函数的。 抽象类的唯一用途是为派生类提供基类，纯虚函数的作用是作为派生类中的成员函数的基础，并实现动态多态性。继承于抽象类的派生类如果不能实现基类中所有的纯虚函数，那么这个派生类也就成了抽象类。因为它继承了基类的抽象函数，只要含有纯虚函数的类就是抽象类。纯虚函数已经在抽象类中定义了这个方法的声明，其它类中只能按照这个接口去实现。 C++接口和抽象类的区别 一般说的接口，表示对外提供的方法，提供给外部调用。是沟通外部跟内部的桥梁。也是以类的形式提供的，但一般该类只具有成员函数，不具有数据成员。 抽象类可以既包含数据成员又包含方法。 基类指针和派生类指针之间的转换 基类指针指向基类对象、派生类指针指向派生类对象。这是正常的。 基类指针指向派生类对象。这种情况是允许的，通过定义一个基类指针和一个派生类对象，把基类指针指向派生类对象，但是需要注意，通常情况这时的指针调用的是基类的成员函数。分四种情况： 函数在基类和派生类中都存在。这时通过指向派生类对象的基类指针调用成员函数，调用的是基类的成员函数。 函数在基类中不存在，在派生类中存在。编译器报错 将基类指针强制转换为派生类指针。这种是向下的强制类型转换，转换之后“指向派生类的基类指针”就可以访问派生类的成员函数 如果基类中的成员函数被定义为虚函数，并且在派生类中也实现了该函数，则通过“指向派生类的基类指针” 访问虚函数，访问的是派生类中的实现。允许“基类指针指向派生类”这个操作，最大的意义也就在此，通过虚函数和函数覆盖，实现了“多态”（指向不同的派生类，实现不同功能）。 派生类指针指向基类对象，会编译错误。基类对象无法被当作派生类对象，派生类中可能具有只有派生类才有的成员或成员函数。即便是使用强制转换，将派生类指针强制转换成基类指针，通过这个“强制指向基类的派生类指针”访问的函数依然是派生类的成员函数。 综上，可以通过基类指针访问派生类方法（强制转换和虚函数），不存在通过派生类指针调用基类成员函数的方法（即便是强制转换）。 C++编译时多态，运行时多态 编译时多态又叫静态联编，主要通过函数重载和运算符重载来实现 运行时多态又叫动态联编，主要通过继承和虚函数来实现 c++11新特性 右值引用与std::move()避免右值对象拷贝 初始化列表 explicit auto auto不会有任何的效率损失，都是基于编译期的推导 auto还会带来更好的安全性 decltype nullptr(与nil等价) default启用编译器提供的默认函数实现 delete关键字禁止生成默认方法实现 static_assert()提供编译期断言 range for constexpr lambda表达式 enum class 构造函数和析构函数能否抛出异常 构造函数可抛出异常。动态创建对象要进行两个操作：分配内存和调用构造函数。若在分配内存时出错，会抛出bad_alloc异常；若在调用构造函数初始化时出错，会不会存在内存泄漏呢？答案是不会。 析构函数也可抛出异常，但不推荐抛出。原因如下： 如果析构函数抛出异常，则异常点之后的程序不会执行，如果析构函数在异常点之后执行了某些必要的动作比如释放某些资源，则这些动作不会执行，会造成诸如资源泄漏的问题。 [正常情况下调用析构函数抛出异常导致资源泄露] 通常异常发生时，c++的机制会调用已经构造对象的析构函数来释放资源，此时若析构函数本身也抛出异常，则前一个异常尚未处理，又有新的异常，会造成程序崩溃的问题。 [在发生异常的情况下调用析构函数抛出异常，会导致程序崩溃] 如果非要抛出异常，解决方案如下： 如果某个操作可能会抛出异常，class应提供一个普通函数（而非析构函数），来执行该操作。目的是给客户一个处理错误的机会。 如果析构函数中异常非抛不可，那就用try catch来将异常吞下，必须要把这种可能发生的异常完全封装在析构函数内部，决不能让它抛出函数之外。 构造函数中有哪些注意事项？ 默认情况下，c++编译器至少为我们写的类增加3个函数 默认构造函数(无参，函数体为空)、默认析构函数(无参，函数体为空)、默认拷贝构造函数(对类中非静态成员属性简单值拷贝) 如果用户定义拷贝构造函数，c++不会再提供任何默认构造函数 如果用户定义了普通构造函数(非拷贝)，c++不再提供默认无参构造，但是会提供默认拷贝构造 构造函数和析构函数可以是虚函数吗？ 构造函数不能为虚函数，而析构函数可以且常常是虚函数。 当一个类打算被用作其它类的基类时，它的析构函数必须是虚的。 析构函数也可以是虚的，甚至是纯虚的。纯虚的析构函数并没有什么作用，是虚的就够了。通常只有在希望将一个类变成抽象类，而这个类又没有合适的函数可以被纯虚化的时候，可以使用纯虚的析构函数来达到目的。 子类析构会调用父类的析构函数吗？执行顺序是什么？ 析构情况需要分类讨论 父类析构函数不是虚函数，并使用父类指针指向子类对象，析构该子类对象时，只会调用父类析构函数，因为不具多态性。如何解决？父类析构函数改为虚函数。 父类析构函数不是虚函数，并使用子类指针指向子类对象，那么会先调用子类析构函数，再调用父类析构函数，子类释放子类中分配的，父类分配父类中分配的。 C++默认成员函数 默认构造函数、默认拷贝构造函数、默认析构函数、默认赋值运算符、取址运算符和取址运算符const 注意，如果一个类中只存在一个参数为&amp;ClassName的拷贝构造函数，那么就不能使用const ClassName或volatile ClassName的对象实行拷贝初始化。 sizeof和strlen sizeof是运算符，strlen是函数 sizeof操作符的结果是size_t，该类型保证能容纳实现所建立的最大对象的字节大小 sizeof可以用类型做参数，strlen只能用char*做参数，且必须以“\\0”结尾 数组作为sizeof的参数不退化，但是传递给strlen时就退化为指针了 大部分编译程序在编译的时候sizeof就被计算过了，这就是sizeof（x）可以作为定义数组维数的原因。strlen的结果要在运行的时候才能计算出来，它用来计算字符串的长度，不是类型占内存的大小。 sizeof后如果是类型必须加括弧，如果变量名可以不加括弧。这是因为sizeof是个操作符，不是个函数。 sizeof计算的是分配的数组所占内存空间的大小，不受里面存储内容的改变而改变。 sizeof用途 与存储分配和I/O系统的例程进行通信 查看某个类型的对象在内存中所占的单元字节 动态分配对象时，可以使系统知道要分配多少内存。 便于一些类型的扩充，在Windows中很多结构类型有一个专用的字段是用来存放该类型的字节大小。 由于操作数的字节数在实现时可能出现变化，建议在涉及到操作数字节大小时用sizeof来代替常量计算。 如果操作数是函数中的数组形参或函数类型的形参，sizeof给出其指针的大小。 内联函数和宏定义的区别 使用宏和内联函数都可以节省在函数调用方面所带来的时间和空间开销。二者都采用了空间换时间的方式，在其调用处进行展开 在预编译时期，宏定义在调用处执行字符串的原样替换。在编译时期，内联函数在调用处展开，同时进行参数类型检查。 内联函数可以作为某个类的成员函数，这样可以使用类的保护成员和私有成员。而当一个表达式涉及到类保护成员或私有成员时，宏就不能实现了(无法将this指针放在合适位置)。 在编写内联函数时，函数体应该短小而简洁，不应该包含循环等较复杂结构，否则编译器不会将其当作内联函数看待，而是把它决议成为一个静态函数。 频繁的调用内联函数和宏定义容易造成代码膨胀，消耗更大的内存而造成过多的换页操作。 C++ shared_ptr - 循环引用，weak_ptr 程序编译过程、静态链接和动态链接等 C++ RAII RAII是Resource Acquisition Is Initialization（wiki上面翻译成 “资源获取就是初始化”）的简称，是C++语言的一种管理资源、避免泄漏的惯用法。利用的就是C++构造的对象最终会被销毁的原则。RAII的做法是使用一个对象，在其构造时获取对应的资源，在对象生命期内控制对资源的访问，使之始终保持有效，最后在对象析构的时候，释放构造时获取的资源。RAII是用来管理资源、避免资源泄漏的方法。 当我们在一个函数内部使用局部变量，当退出了这个局部变量的作用域时，这个变量也就被销毁了；当这个变量是类对象时，这个时候，就会自动调用这个类的析构函数，而这一切都是自动发生的，不要程序员显示的去调用完成。RAII就是这样去完成的。 由于系统的资源不具有自动释放的功能，而C++中的类具有自动调用析构函数的功能。如果把资源用类进行封装起来，对资源操作都封装在类的内部，在析构函数中进行释放资源。当定义的局部变量的生命结束时，它的析构函数就会自动的被调用，如此，就不用程序员显示的去调用释放资源的操作了。 作者：zhaozhengcoder链接：https://www.jianshu.com/p/b7ffe79498be来源：简书著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 C++ static static关键词作用于成员变量和成员函数 静态变量作用范围在一个文件内，程序开始时分配空间，结束时释放空间，默认初始化为0，使用时可以改变其值。静态变量或静态函数只有本文件内的代码才能访问它，它的名字在其它文件中不可见。 函数内部声明的static变量，可作为对象间的一种通信机制。如果一局部变量被声明为static，那么将只有唯一的一个静态分配的对象，它被用于在该函数的所有调用中表示这个变量。这个对象将只在执行线程第一次到达它的定义使初始化。 对于局部静态对象，构造函数是在控制线程第一次通过该对象的定义时调用。在程序结束时，局部静态对象的析构函数将按照他们被构造的相反顺序逐一调用，没有规定确切时间。 如果一个变量是类的一部分，但却不是该类的各个对象的一部分，它就被成为是一个static静态成员。一个static成员只有唯一的一份副本，而不像常规的非static成员那样在每个对象里各有一份副本。同理，一个需要访问类成员，而不需要针对特定对象去调用的函数，也被称为一个static成员函数。 类的静态成员函数只能访问类的静态成员(变量或函数)。 shared_ptr 线程安全，引用计数如何实现的，原子操作的原理 shared_ptr在C++11版本之后提供，包含在头文件&lt;memory&gt;中，有shared_ptr,unique_ptr和weak_ptr。 有关于内存分配的问题，怎么实现自主在堆中进行内存分配(因为我自己实现了malloc函数，所以就是简单回答用sbrk() 的系统调用对于堆进行内存分配) 1G内存，void * p = malloc(1.2g) 可行吗，用 for 循环对所分配的内存依次写入，到后面会发生什么，哪些会被置换, 32位系统的进程空间分布，malloc的内存在哪里， p 呢 实现一个C++string operator=()函数, 白纸写. 这个写的还可以, 要注意的点 : 自身复制, 异常安全. 实现strncpy函数, 没啥毛病, 注意鲁棒性 空对象的大小，加虚析构函数又怎样呢。 空对象大小为1，加了虚析构函数就是指针大小，32位系统大小为4，64位系统大小为8 假设我现在开辟了一片共享内存，然后我想在这块共享内存上使用stl库，该怎么做呢。比如说我使用vector，我想要它的元素全部在共享内存上，就算是新添加的元素也是被分配在共享内存上。（我们可以重写一个allocator，把共享内存划分给它，用这些共享内存实现一个内存池，让allocator来对它进行管理） 把C++多态的实现讲一下吧（从虚表表、虚函数表、虚函数表指针去具体介绍，然后介绍了构造析构过程中虚函数表指针的变化过程，然后从这些变化过程去解释语言级别的现象） gcc选项知道哪些（-O优化选项、-W加强警告…还有分阶段编译：-E预编译生成.i文件，-S预编译+编译生成.s文件，-c生成.o文件，-o指定输出文件，-l指定链接库，差不多用得多的就这些了）加调试信息（-gstabs）多线程编译呢（不支持） 介绍一下STL allocator 介绍一下迭代器与容器之间的耦合关系（在SGI STL中只有容器对迭代器的依赖关系，而迭代器并没有对容器的耦合关系。所以，比如说vector扩容之后，迭代器会失效，解引用这样的迭代器可能会造成非法访问。但是以前用VisualStudio使用它的C++的STL库CRT的时候，如果容器进行了扩容，然后解引用它们已失效的迭代器的时候，会引发异常。所以我猜想它们的实现里，一定是将迭代器与容器进行了关联，每次对迭代器进行操作时候，都会根据容器检验迭代器的有效性，如果无效就抛出异常。） 类型萃取有什么作用 C++模板中的类型参数T是抽象的，我们并不能在模板内部直接获得它的具体特征。类型萃取（抽取）技术就是要抽取类型的一些具体特征(trait)，比如它是哪种具体类型，它是引用类型，内建类型，还是类类型等。可见，类型萃取技术其实就是trait模板技术的具体体现。 类型信息是编译期的实体，现在要针对类型来进行编程，这其实就是模板元编程的一个方面。我们平常使用的if/else，while，for等基本的逻辑结构都是运行期的行为，在面向类型的编程中并不能使用，这就需要用到一些特殊的模板技术。实现类型萃取要用到的基本思想一个是特化，一个就是用typedef来携带类型信息。实际上，我们在用模板做设计时，一般建议在模板定义内部，为模板的每个类型参数提供typedef定义，这样在泛型代码中可以很容易地访问或抽取这些类型。 在C和C++中，普通的函数可以称为值函数，它们接受的参数是某些值，返回的结果也是值。而所谓的类型函数接受的实参是类型，返回的是被抽取出来的类型或常量值等（即用typedef定义的类型别名，一般不同的具体类型都定义统一的别名）。如类模板就是类型函数，sizeof是内建的类型函数，返回给定类型实参的大小。在类型编程中，很多地方都要用到sizeof。 hashmap底层实现原理，hashmap存储结构怎么样，怎么处理的hash冲突，当查询时，其时间复杂度怎么样 gdb用过吗？可以，那来讲下死锁应该怎么调试吧 查内存泄露用什么工具？自己使用过么 Java和C++的最主要的区别是什么 第一点是，在C++中，支持面向过程，函数可以与类隔离单独存在，而Java的函数必须在类里面。第二点是内存管理，C++需要程序员自己去管理内存，而Java是通过垃圾回收自动管理内存。（关于多继承和单继承的区别忘记回答了。。接口也忘了回答了，有点紧张） 怎么弄出一个不能被继承的类 https://www.cnblogs.com/yanenquan/p/4006691.html","categories":[],"tags":[]},{"title":"NLG评估指标chrF、chrF++介绍","slug":"chrf","date":"2021-03-24T10:45:09.000Z","updated":"2021-03-24T10:47:00.489Z","comments":true,"path":"2021/03/24/chrf/","link":"","permalink":"http://example.com/2021/03/24/chrf/","excerpt":"","text":"@TOC 一、CHRF这个方法比较新，我找到的论文是2015年的。所以网上资料不多。建议如果不了解【BLEU】的话建议先去找篇博客大概看一下，网上很多。然后在了解的基础上，才能更好理解chrF。 论文解读： 1. 基础 CHRF和BLEU类指标的最大不同之处在于，BLEU是单词级的，CHRF是字符级的，也就是基于字符n-gram计算的。 通用的公式：$$chrF\\beta = (1+\\beta ^{2}) \\frac{chrP·chrR}{\\beta ^{2}·chrP+chrR}$$其中： chrP是精确度（查准率），就是候选文和参考文匹配的字符级n-gram在候选文中占的比例。 chrR是召唤率（查全率），就是候选文和参考文匹配的字符级n-gram在参考文中占的比例。 那么当β=1时就是CHRF，当β=2时就是CHRF2，当β=3时就是CHRF3。论文当中使用的是β=3来做实验，而且并没说明为什么用3，只是一个初始值。论文最后也有提到应该多对β的值做做后续研究，以便改良。 2. 实验 实验数据集为对WMT12, WMT13 以及WMT14。 实验对CHRF和CHRF3以及WORDF对比BLEU、TER、METEOR等标准方法，发现CHRF3的表现最好。 二、CHRF++CHRF++其实就是CHRF的改进，所以就更新了，论文是在2017年发表的。而且和CHRF的是同一个作者。 论文解读： 论文开头提到别人研究过β最好为2，这一点论文后面也实验确认过。 CHRF++其实和CHRF差不多。但是CHRF++是字符级和单词级都用到了，然后算一个平均值。 论文中提到别人研究过字符级n-gram的n最好不要超过6，单词级n-gram的n最好不要超过4。 CHRF++的字符级n-gram的n最好是6，单词级n-gram的n最好是1或2。 三、代码实现以及论文链接 CHRF： 1234567nltk.translate.chrf_score #在这个包中有好几个计算CHRF的函数&#x27;&#x27;&#x27;下面是包内函数&#x27;&#x27;&#x27;nltk.translate.chrf_score.sentence_chrf #这个函数是实现的论文的nltk.translate.chrf_score.chrf_precision_recall_fscore_support nltk.translate.chrf_score.corpus_chrf &#x27;&#x27;&#x27;具体使用看函数介绍或者文档吧&#x27;&#x27;&#x27;&#x27;&#x27;&#x27;推荐文档地址:http://www.nltk.org/api/nltk.translate.html?highlight=chrf#module-nltk.translate.chrf_score&#x27;&#x27;&#x27; 论文链接 CHRF++ 论文给的实现代码链接 论文链接","categories":[],"tags":[]},{"title":"CCF大数据比赛--severless工作负载预测  0.33分方案分享","slug":"CCF","date":"2021-03-24T10:36:47.000Z","updated":"2021-03-24T10:36:55.970Z","comments":true,"path":"2021/03/24/CCF/","link":"","permalink":"http://example.com/2021/03/24/CCF/","excerpt":"","text":"@TOC 一、赛题理解 赛题难点就在于上面那张图，到了某个点后接下来的趋势到底是怎样的？继续上升还是下降还是保持平稳。 这道赛题让我们用过去五个点预测接下来五个点，按道理时序模型里面越近的时间点对当前时间点的预测意义越重，那么这里只有五个的话其实很难单个拎出来说哪个点的意义更大。 一上来我先交了五个时间点CPU使用率和排队job数的平均值、最大值、最小值、中位数、最小三个数的平均值，其中平均值分数0.08左右，最小三个数的平均值分数在0.11左右，有一个忘记了，最高是0.12的。从这里还有评价指标可以看出，其实直接用平均值这些统计值对于预测意义已经不错了，像我最高分是在0.33，将近0.34，这个分数对比0.12算出来的精度其实就差几个百分点。 根据很多大佬的言论以及我的总结觉得对于排队中的job数的预测过于玄学，而且占比不大，主战场还是CPU使用率，所以我后面的分享基本都是基于如何预测CPU使用率的。 二、数据分析1.excel分析 训练集数据间时间间隔基本都不是5分钟的，但大多数还是在3-30分钟内。其中极值甚至可以上千分钟。但训练集是严格5分钟的。 训练集存在缺失值的情况，比如磁盘使用率，但是缺失值也不是很多。 训练集里面很多队列在测试集都没出现的。 测试集的大概15000条样本中光是297号队列就占了5710条，其次是21487和85153号队列，分别占了2235和1950条，记起来将近2/3。所以对这几个队列的预测精度可谓是提分大头。 测试集的日期做了脱敏处理。 2.python分析 做了折线图、散点图和条形图什么的最基本的统计图。可以看出其实大部分时候CPU的使用率都是偏低的，不管是平均值还是中位数基本都是在个位数。 不同队列的分布相差较大，有的队列的CPU使用率基本都比一些其他队列大。 三、数据预处理 针对缺失值问题我采用了直接删掉对应样本和补0两种方法，两种方法效果差不多，大概有几个千分点的提分。 针对时间间隔不均匀的问题，在构造训练集时我设置了一个阈值，当前后两个时间点的时间间隔大于这个阈值时自动丢弃这个样本（比如t1-t0&gt;阈值）,但这个是掉分操作。 针对时间间隔不均匀的问题，我一个朋友做了插值处理后重采样。但结果是掉分的。原因我分析大概是插值后增大了误差，因为插值出来的数据可能过于不准确。 时间转化为了y-m-d格式。 四、特征工程 因为heng哥的baseline是每个队列都建立不同的模型，所以删除每个队列都有相同数据列很合理，其中有 根据前面的作图我发现一天当中的不同时段CPU的使用率分布还是有很大区别的，所以加入了 （hour*60+min）的时间特征。事实证明这个提分非常大，几个百分点的提分，在前期让我直接坐上榜二的位置。 根据鱼佬的baseline的灵感，加入了滑窗统计值和衰减统计值以及组合特征，基本都是掉分的。 五、模型 选用模型：用的模型就是heng哥baseline的lgb模型，没有什么特别之处。 调参：对树深和K折交叉的参数都调大了，大概是1-2个百分点的提升。 模型融合时选用了xgboost和随机森林，分数分别在0.32和0.312。但是无论以加权平均数融合还是采用stacking融合都没有lgb单模高分（heng哥nb！），猜测原因是模型相似度太高且融合模型有点少。 六、后处理 因为测试集的分布和训练集不一致，测试集的CPU使用率偏高一点，所以我给结果整体加/乘上了一个小常数 ，使它更好的拟合测试集，感觉这其实是玄学做法，但是有几个千分点的提分。 对于排队中的job数这个预测值，我直接采用平均值。结果比我模型预测的高将近1个百分点吧。 七、一些别的发现和思考 长时间上不了分后，我开始手动观察结果，发现我模型中的一些问题，比如我有一个很明显的误差很大的结果： 测试集CPU使用率 CPU使用率预测值 85 2 85 1 91 1 91 1 90 1 这里很明显用肉眼都能观察出不合理，应该是过拟合导致，但是发现时已经是赛程末期，做了一下缓解过拟合的操作反而掉分了就放弃挣扎了。 学业太忙一直没能把神经网络弄出来，结合一些大佬的言论，感觉应该是个上分点，有兴趣的可以试试。 总结这道赛题出的业务场景还是很不错的。虽然我第一眼看上去很简单，但是实际做起来却还是蛮有讲究的。当然对于我这个方案，不足之处和可改善之处还很多，等学习了前排方案后我再来改进一下自己的方案吧。 致谢首先感谢zhengheng大哥的baseline，没有这份baseline，对于我这种菜鸟新手真的不知从何开始，真的感谢！然后感谢我的导师和我的师兄还有给我提供过思路的队友以及朋友们，你们的支持是我继续打下去的动力！最后献上我的代码：开源代码","categories":[],"tags":[]}],"categories":[],"tags":[]}